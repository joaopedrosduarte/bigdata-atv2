# Pipeline de Dados para AnÃ¡lise de Filmes
## Fundamentos de Big Data - AV1

![Status](https://img.shields.io/badge/Status-ConcluÃ­do-success)
![Python](https://img.shields.io/badge/Python-3.8+-blue)
![License](https://img.shields.io/badge/License-MIT-green)

---

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto implementa um **pipeline completo de dados em batch** utilizando a **arquitetura Medallion** (Bronze â†’ Silver â†’ Gold) para processar, limpar e analisar dados de filmes. O objetivo Ã© demonstrar boas prÃ¡ticas de engenharia de dados, desde a ingestÃ£o atÃ© a geraÃ§Ã£o de insights atravÃ©s de anÃ¡lises exploratÃ³rias e modelagem preditiva.

O pipeline transforma dados brutos de ~45 mil filmes em datasets analÃ­ticos prontos para consumo, incluindo:
- Limpeza e padronizaÃ§Ã£o de dados
- Enriquecimento com features derivadas (ROI, densidade de votos)
- AnÃ¡lises de correlaÃ§Ã£o comparativas
- Baseline de Machine Learning para prediÃ§Ã£o de avaliaÃ§Ãµes

---

## ğŸ‘¥ Equipe

| Nome |
|------|
| **JoÃ£o Pedro Duarte de Souza** |
| **Antony Kevin Delgado Silva** |
| **Beatriz Vilarim** |

---

## ğŸ“Š Fonte dos Dados

### Dataset: The Movies Dataset
- **Fonte**: [Kaggle - The Movies Dataset](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset)
- **Arquivo principal**: `movies_metadata.csv`
- **Volume**: ~45.466 registros
- **Formato original**: CSV (8 MB)
- **Atributos principais**:
  - InformaÃ§Ãµes bÃ¡sicas (tÃ­tulo, data de lanÃ§amento, idioma)
  - MÃ©tricas financeiras (orÃ§amento, receita)
  - AvaliaÃ§Ãµes (vote_average, vote_count, popularity)
  - Metadados (gÃªneros, produtoras)

### MÃ©todos de IngestÃ£o Suportados
1. **Kaggle API** (automÃ¡tico via token)
2. **Google Drive** (integraÃ§Ã£o com Colab)
3. **Upload Manual** (arquivo local)

---

## ğŸ› ï¸ Ferramentas e Tecnologias Aplicadas

### Stack Principal

| Categoria | Tecnologia | VersÃ£o | Finalidade |
|-----------|-----------|--------|------------|
| **Linguagem** | Python | 3.8+ | Linguagem principal do pipeline |
| **Processamento** | Pandas | 2.0+ | ManipulaÃ§Ã£o e transformaÃ§Ã£o de dados |
| **Armazenamento** | Parquet (PyArrow) | - | Formato colunar eficiente e comprimido |
| **VisualizaÃ§Ã£o** | Matplotlib | 3.7+ | GrÃ¡ficos bÃ¡sicos (histogramas, scatter plots) |
| **VisualizaÃ§Ã£o** | Seaborn | 0.12+ | Heatmaps de correlaÃ§Ã£o estatÃ­stica |
| **Machine Learning** | Scikit-learn | 1.3+ | Baseline de modelagem (RegressÃ£o Linear) |
| **Ambiente** | Jupyter Notebook | - | Desenvolvimento interativo |
| **Ambiente** | Google Colab | - | ExecuÃ§Ã£o em nuvem (opcional) |

### Bibliotecas Auxiliares
- **NumPy**: OperaÃ§Ãµes numÃ©ricas e arrays
- **json/ast**: Parsing de campos JSON-like
- **pathlib**: ManipulaÃ§Ã£o de caminhos de arquivos
- **datetime**: Processamento de datas

---

## ğŸ—ï¸ Arquitetura do Pipeline

### Arquitetura Medallion (3 Camadas)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAW   â”‚  â†’   â”‚ BRONZE  â”‚  â†’   â”‚ SILVER  â”‚  â†’   â”‚  GOLD   â”‚
â”‚  (CSV)  â”‚      â”‚(Parquet)â”‚      â”‚(Parquet)â”‚      â”‚(Parquet)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   8 MB            2 MB             2.5 MB           1.5 MB
  45.466          45.466           45.436           45.436
   24 cols        24 cols          32 cols          15 cols
```

### TransformaÃ§Ãµes por Camada

#### ğŸ¥‰ Bronze - PadronizaÃ§Ã£o
- Leitura robusta do CSV (encoding, delimitadores)
- NormalizaÃ§Ã£o de nomes de colunas (snake_case)
- ConversÃ£o para formato Parquet
- **Sem transformaÃ§Ãµes semÃ¢nticas** (dados brutos preservados)

#### ğŸ¥ˆ Silver - Limpeza e Enriquecimento
- CoerÃ§Ã£o de tipos numÃ©ricos (budget, revenue, popularity, runtime)
- Parsing de datas (release_date â†’ datetime)
- ExtraÃ§Ã£o de campos derivados (release_year)
- Parsing de campos JSON (genres, production_companies)
- **Feature Engineering**:
  - `ROI` = revenue / budget
  - `vote_density` = vote_count / (anos desde lanÃ§amento + 1)
  - `years_since_release` = ano atual - release_year
- RemoÃ§Ã£o de duplicatas
- ValidaÃ§Ã£o de qualidade de dados

#### ğŸ¥‡ Gold - Datasets AnalÃ­ticos
- SeleÃ§Ã£o de colunas core para anÃ¡lise
- AgregaÃ§Ãµes e sumarizaÃ§Ãµes
- Exports em mÃºltiplos formatos (Parquet + CSV)
- Datasets prontos para consumo (BI, ML, dashboards)

---

## ğŸ“ˆ AnÃ¡lises Implementadas

### 1. AnÃ¡lise de CorrelaÃ§Ã£o Comparativa
- **Heatmaps lado a lado** (Bronze vs Silver)
- IdentificaÃ§Ã£o de correlaÃ§Ãµes fortes (|r| > 0.5)
- Justificativa para seleÃ§Ã£o de features
- VisualizaÃ§Ã£o do impacto das transformaÃ§Ãµes

### 2. AnÃ¡lise ExploratÃ³ria de Dados (EDA)
- DistribuiÃ§Ã£o de avaliaÃ§Ãµes (histograma de vote_average)
- RelaÃ§Ã£o orÃ§amento Ã— receita (scatter plot)
- Top 10 gÃªneros por mÃ©dia de nota
- EstatÃ­sticas descritivas completas

### 3. Baseline de Machine Learning
- **Modelo**: RegressÃ£o Linear
- **VariÃ¡vel-alvo**: `vote_average`
- **Features**: runtime, popularity, vote_count, budget, revenue, years_since_release, vote_density
- **MÃ©tricas obtidas**:
  - RÂ² = 0.0452
  - MAE (Erro MÃ©dio Absoluto) = 1.3084

---

## ğŸ“ Estrutura do Projeto

```
bigdata-atv1/
â”‚
â”œâ”€â”€ README.md                                    # Este arquivo
â”œâ”€â”€ dados/
â”‚   â”œâ”€â”€ raw/                                     # CSV original (nÃ£o versionado)
â”‚   â”‚   â””â”€â”€ movies_metadata.csv
â”‚   â”œâ”€â”€ bronze/                                  # Parquet bruto padronizado
â”‚   â”‚   â””â”€â”€ movies_metadata_bronze.parquet
â”‚   â”œâ”€â”€ silver/                                  # Parquet limpo e enriquecido
â”‚   â”‚   â””â”€â”€ movies_metadata_silver.parquet
â”‚   â””â”€â”€ gold/                                    # Datasets finais
â”‚       â”œâ”€â”€ movies_metadata_gold.parquet
â”‚       â”œâ”€â”€ gold_describe.csv
â”‚       â””â”€â”€ gold_sample.csv
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ Projeto_BigData_Movies_Pipeline.ipynb   # Notebook principal
â”‚
â”œâ”€â”€ documentacao/
â”‚   â”œâ”€â”€ ARQUITETURA_PIPELINE.md                 # DocumentaÃ§Ã£o tÃ©cnica
â”‚   â””â”€â”€ DIAGRAMA_PIPELINE.md                    # Diagrama visual do fluxo
â”‚
â””â”€â”€ .gitignore                                   # Arquivos ignorados pelo Git
```

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

```bash
Python 3.8+
pip (gerenciador de pacotes)
```

### InstalaÃ§Ã£o de DependÃªncias

```bash
pip install pandas numpy pyarrow fastparquet scikit-learn matplotlib seaborn
```

### ExecuÃ§Ã£o do Pipeline

#### OpÃ§Ã£o 1: Jupyter Notebook (Local)

```bash
# Clone o repositÃ³rio
git clone <url-do-repositorio>
cd bigdata-atv1

# Baixe o dataset do Kaggle para dados/raw/
# https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset

# Abra o notebook
jupyter notebook src/Projeto_BigData_Movies_Pipeline.ipynb

# Execute todas as cÃ©lulas sequencialmente
```

#### OpÃ§Ã£o 2: Google Colab

1. FaÃ§a upload do notebook para o Google Drive
2. Abra com Google Colab
3. Configure a fonte de dados (Kaggle API, Drive ou Upload)
4. Execute todas as cÃ©lulas

### Ordem de ExecuÃ§Ã£o
1. **Setup** (instalar libs e criar estrutura de pastas)
2. **IngestÃ£o** (carregar movies_metadata.csv)
3. **Bronze** â†’ **Silver** â†’ **Gold** (executar transformaÃ§Ãµes)
4. **AnÃ¡lises** (heatmaps, EDA, modelagem)
5. **Destino** (exports finais)

---

## ğŸ“Š Resultados Obtidos

### MÃ©tricas do Pipeline

| MÃ©trica | Valor |
|---------|-------|
| Registros processados | 45.466 |
| Registros apÃ³s limpeza | 45.436 (99,93%) |
| Features criadas | 8 (3 derivadas + 5 transformadas) |
| ReduÃ§Ã£o de tamanho | 81% (8MB â†’ 1.5MB no Gold) |
| Tempo de execuÃ§Ã£o | ~2-3 minutos |

### Insights Principais

1. **CorrelaÃ§Ãµes mais fortes**:
   - `budget` â†” `revenue`: r = 0.73 (correlaÃ§Ã£o forte positiva)
   - `vote_count` â†” `popularity`: r = 0.79 (alta relaÃ§Ã£o)

2. **Features mais relevantes para prediÃ§Ã£o**:
   - `vote_count`: maior correlaÃ§Ã£o com vote_average
   - `popularity`: segunda mais relevante
   - `runtime`: correlaÃ§Ã£o moderada

3. **Qualidade de dados**:
   - 99,93% dos registros aproveitados
   - 30 duplicatas removidas
   - Valores ausentes tratados adequadamente

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **[ARQUITETURA_PIPELINE.md](./documentacao/ARQUITETURA_PIPELINE.md)**: DocumentaÃ§Ã£o tÃ©cnica completa, tecnologias propostas, roadmap
- **[DIAGRAMA_PIPELINE.md](./documentacao/DIAGRAMA_PIPELINE.md)**: Diagrama visual detalhado do fluxo de dados

---

## ğŸ¯ Status do Projeto

### Checklist AV1

- [x] **IngestÃ£o**: Finalizado âœ…
  - Leitura de CSV com mÃºltiplas fontes (Kaggle, Drive, Upload)
  - Tratamento robusto de encoding e delimitadores

- [x] **Armazenamento**: Finalizado âœ…
  - Estrutura Medallion (Bronze/Silver/Gold) implementada
  - ConversÃ£o para formato Parquet com compressÃ£o
  - Exports adicionais em CSV para consumo

- [x] **TransformaÃ§Ã£o**: Finalizado âœ…
  - Limpeza e tipagem de dados
  - Feature engineering (ROI, vote_density, years_since_release)
  - Parsing de campos JSON
  - RemoÃ§Ã£o de duplicatas e validaÃ§Ã£o de qualidade

- [x] **AnÃ¡lise**: Finalizado âœ…
  - Heatmaps de correlaÃ§Ã£o comparativos (Bronze vs Silver)
  - EDA completa com histogramas e scatter plots
  - Baseline de modelagem (RegressÃ£o Linear)
  - MÃ©tricas: RÂ² = 0.0452, MAE = 1.3084

---

## ğŸ”® PrÃ³ximos Passos (Roadmap)

### Curto Prazo
- [ ] Implementar testes automatizados de schema
- [ ] Adicionar logging estruturado
- [ ] Versionar datasets com DVC (Data Version Control)

### MÃ©dio Prazo
- [ ] Migrar para AWS S3 + Glue
- [ ] Implementar orquestraÃ§Ã£o com Apache Airflow
- [ ] Criar dashboard interativo (Streamlit/Plotly)

### Longo Prazo
- [ ] Deploy em produÃ§Ã£o com CI/CD
- [ ] Monitoramento com Prometheus + Grafana
- [ ] Escalar para outros datasets do Kaggle

---

## ğŸ“ LicenÃ§a

Este projeto foi desenvolvido para fins acadÃªmicos como parte da disciplina **Fundamentos de Big Data**.

---

## ğŸ“§ Contato

Para dÃºvidas ou sugestÃµes sobre o projeto, entre em contato com a equipe atravÃ©s dos canais da disciplina.

---

**Desenvolvido com â¤ï¸ pela equipe de Big Data**

*Ãšltima atualizaÃ§Ã£o: 12 de Outubro de 2025*
