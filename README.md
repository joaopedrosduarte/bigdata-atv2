# Pipeline de Dados para AnÃ¡lise de Filmes
## Fundamentos de Big Data - Projeto Final (AV2)

![Status](https://img.shields.io/badge/Status-ConcluÃ­do-success)
![Python](https://img.shields.io/badge/Python-3.8+-blue)
![License](https://img.shields.io/badge/License-MIT-green)

---

## ğŸ“‹ 1. IntroduÃ§Ã£o

### 1.1 ApresentaÃ§Ã£o do Tema

Este projeto implementa um **pipeline completo de Big Data** para anÃ¡lise e prediÃ§Ã£o de mÃ©tricas de filmes, utilizando um dataset com aproximadamente 45 mil filmes do Kaggle. O trabalho abrange todas as etapas de um pipeline moderno de dados, desde a ingestÃ£o de dados brutos atÃ© a disponibilizaÃ§Ã£o de insights atravÃ©s de visualizaÃ§Ãµes e modelos preditivos.

### 1.2 Contexto e Problema

A indÃºstria cinematogrÃ¡fica movimenta bilhÃµes de dÃ³lares anualmente, e entender os fatores que influenciam o sucesso de um filme Ã© crucial para estÃºdios, produtores e investidores. No entanto, os dados disponÃ­veis sobre filmes frequentemente apresentam desafios:

- **Dados nÃ£o estruturados**: InformaÃ§Ãµes como gÃªneros e produtoras armazenadas em formato JSON dentro de arquivos CSV
- **Qualidade inconsistente**: Valores ausentes, duplicatas e erros de tipagem
- **Volume significativo**: Dezenas de milhares de registros histÃ³ricos
- **MÃºltiplas dimensÃµes**: Dados financeiros, avaliaÃ§Ãµes, metadados temporais e categÃ³ricos

**Problema Central**: Como processar, limpar e extrair insights valiosos de dados cinematogrÃ¡ficos para responder perguntas como:
- Quais fatores influenciam a avaliaÃ§Ã£o mÃ©dia de um filme?
- Existe correlaÃ§Ã£o entre orÃ§amento e receita?
- Como as avaliaÃ§Ãµes variam ao longo do tempo?
- Ã‰ possÃ­vel prever o sucesso de um filme com base em suas caracterÃ­sticas?

---

## ğŸ“Š 2. MotivaÃ§Ã£o

### 2.1 RelevÃ¢ncia do Projeto

A escolha deste projeto se justifica por diversos fatores:

1. **Aplicabilidade PrÃ¡tica**: O pipeline desenvolvido pode ser adaptado para problemas reais da indÃºstria do entretenimento, auxiliando em decisÃµes de investimento e estratÃ©gias de marketing.

2. **DemonstraÃ§Ã£o de CompetÃªncias em Big Data**: O projeto permite aplicar conceitos fundamentais de engenharia de dados:
   - Arquitetura Medallion (Bronze, Silver, Gold)
   - ETL/ELT (Extract, Transform, Load)
   - Data Quality e Data Governance
   - Feature Engineering
   - AnÃ¡lise exploratÃ³ria de dados (EDA)

3. **Complexidade TÃ©cnica Adequada**: O dataset escolhido apresenta desafios reais (dados semi-estruturados, limpeza necessÃ¡ria, volume significativo), sem ser inviÃ¡vel para um projeto acadÃªmico.

4. **Potencial AnalÃ­tico**: Os dados permitem mÃºltiplas anÃ¡lises interessantes, desde correlaÃ§Ãµes simples atÃ© modelagem preditiva e anÃ¡lise temporal.

### 2.2 Justificativa da Escolha do Dataset

O dataset "The Movies Dataset" do Kaggle foi escolhido por:

- **Qualidade e Confiabilidade**: Proveniente de fonte respeitada (Kaggle) com mais de 5.000 downloads
- **Riqueza de InformaÃ§Ãµes**: ContÃ©m mÃ©tricas financeiras, avaliaÃ§Ãµes, metadados e informaÃ§Ãµes temporais
- **Desafios Reais**: PresenÃ§a de dados semi-estruturados (JSON), valores ausentes e inconsistÃªncias
- **Volume Adequado**: ~45K registros - suficiente para demonstrar tÃ©cnicas de Big Data sem exigir infraestrutura excessiva
- **DocumentaÃ§Ã£o DisponÃ­vel**: Dataset bem documentado com descriÃ§Ãµes claras dos campos

---

## ğŸ¯ 3. Objetivo do Projeto

### 3.1 Objetivo Geral

Desenvolver um **pipeline completo de Big Data** para ingestÃ£o, processamento, anÃ¡lise e disponibilizaÃ§Ã£o de dados cinematogrÃ¡ficos, aplicando boas prÃ¡ticas de engenharia de dados e gerando insights acionÃ¡veis sobre fatores que influenciam o sucesso de filmes.

### 3.2 Objetivos EspecÃ­ficos

1. **Implementar Arquitetura Medallion**:
   - Camada Bronze: PadronizaÃ§Ã£o e armazenamento de dados brutos
   - Camada Silver: Limpeza, transformaÃ§Ã£o e enriquecimento
   - Camada Gold: Datasets analÃ­ticos prontos para consumo

2. **Garantir Qualidade de Dados**:
   - Tratamento de valores ausentes
   - RemoÃ§Ã£o de duplicatas
   - ValidaÃ§Ã£o de tipos de dados
   - Parsing de campos semi-estruturados (JSON)

3. **Realizar Feature Engineering**:
   - Criar mÃ©tricas derivadas (ROI, densidade de votos)
   - Extrair informaÃ§Ãµes temporais
   - Normalizar e padronizar dados

4. **Gerar Insights AnalÃ­ticos**:
   - Identificar correlaÃ§Ãµes entre variÃ¡veis
   - Analisar distribuiÃ§Ãµes e padrÃµes
   - Criar visualizaÃ§Ãµes informativas

5. **Implementar Baseline de Machine Learning**:
   - Desenvolver modelo preditivo para avaliaÃ§Ãµes
   - Avaliar performance com mÃ©tricas apropriadas
   - Identificar features mais relevantes

6. **Documentar e Versionar**:
   - Manter cÃ³digo versionado no GitHub
   - Documentar decisÃµes tÃ©cnicas
   - Seguir boas prÃ¡ticas de desenvolvimento

---

## ğŸ‘¥ 4. Equipe

| Nome | Papel |
|------|-------|
| **JoÃ£o Pedro Duarte de Souza** | Engenheiro de Dados - Camada Gold, AnÃ¡lise e DocumentaÃ§Ã£o |
| **Anthony Kevin Delgado Silva** | Engenheiro de Dados - Camada Bronze e IngestÃ£o |
| **Beatriz Vilarim** | Engenheira de Dados - Camada Silver e TransformaÃ§Ãµes |

---

## ğŸ”¬ 5. Metodologia (Pipeline de Dados)

Esta seÃ§Ã£o detalha cada etapa do pipeline de dados implementado, seguindo as melhores prÃ¡ticas de engenharia de dados e a arquitetura Medallion.

### 5.1 VisÃ£o Geral do Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FONTES    â”‚  â†’   â”‚  INGESTÃƒO   â”‚  â†’   â”‚TRANSFORMAÃ‡ÃƒOâ”‚  â†’   â”‚CARREGAMENTO â”‚  â†’   â”‚   DESTINO   â”‚
â”‚             â”‚      â”‚   (Batch)   â”‚      â”‚   (ETL)     â”‚      â”‚   (Load)    â”‚      â”‚ (Analytics) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Kaggle CSV           Pandas Read        Bronzeâ†’Silverâ†’         Parquet/CSV         Jupyter/Colab
                                               Gold                Export              Visualizations
```

### 5.2 Etapa 1: Fontes de Dados (Data Sources)

#### DescriÃ§Ã£o
A fonte de dados principal deste projeto Ã© o dataset **"The Movies Dataset"** disponÃ­vel no Kaggle, que contÃ©m informaÃ§Ãµes abrangentes sobre filmes.

#### CaracterÃ­sticas dos Dados

**Dataset Principal**: `movies_metadata.csv`

| CaracterÃ­stica | Detalhes |
|----------------|----------|
| **Fonte** | [Kaggle - The Movies Dataset](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset) |
| **Formato Original** | CSV (Comma-Separated Values) |
| **Tamanho do Arquivo** | ~8 MB (comprimido) |
| **NÃºmero de Registros** | 45.466 filmes |
| **NÃºmero de Colunas** | 24 atributos |
| **PerÃ­odo Coberto** | Filmes desde 1874 atÃ© 2017 |
| **Encoding** | UTF-8 |

#### Estrutura de Dados

**Categorias de InformaÃ§Ã£o**:

1. **Identificadores**:
   - `id`: ID Ãºnico do filme
   - `imdb_id`: ID no IMDb

2. **InformaÃ§Ãµes BÃ¡sicas**:
   - `title`: TÃ­tulo do filme
   - `original_title`: TÃ­tulo original
   - `original_language`: Idioma original
   - `overview`: Sinopse do filme

3. **Dados Temporais**:
   - `release_date`: Data de lanÃ§amento (formato: YYYY-MM-DD)

4. **MÃ©tricas Financeiras**:
   - `budget`: OrÃ§amento de produÃ§Ã£o (USD)
   - `revenue`: Receita total (USD)

5. **AvaliaÃ§Ãµes e Popularidade**:
   - `vote_average`: Nota mÃ©dia (escala 0-10)
   - `vote_count`: NÃºmero total de votos
   - `popularity`: Ãndice de popularidade

6. **Metadados Complexos** (formato JSON dentro do CSV):
   - `genres`: Lista de gÃªneros
   - `production_companies`: Produtoras envolvidas
   - `production_countries`: PaÃ­ses de produÃ§Ã£o
   - `spoken_languages`: Idiomas falados

7. **InformaÃ§Ãµes Adicionais**:
   - `runtime`: DuraÃ§Ã£o em minutos
   - `status`: Status do filme (Released, Post Production, etc.)
   - `tagline`: Slogan do filme
   - `homepage`: Website oficial

#### Tipos de Dados
- **Estruturados**: NumÃ©ricos (budget, revenue, runtime), datas, textos simples
- **Semi-estruturados**: Campos JSON (genres, production_companies)
- **Textuais**: DescriÃ§Ãµes, tÃ­tulos, taglines

### 5.3 Etapa 2: IngestÃ£o (Ingestion)

#### DescriÃ§Ã£o
Processo de coleta e carregamento dos dados brutos das fontes externas para dentro do ambiente de processamento.

#### Tecnologias Utilizadas

| Componente | Tecnologia | Finalidade |
|------------|------------|------------|
| **Linguagem** | Python 3.8+ | ExecuÃ§Ã£o do pipeline |
| **Biblioteca de Leitura** | Pandas `read_csv()` | Parsing de arquivos CSV |
| **Biblioteca HTTP** | `requests` | Download de arquivos (quando necessÃ¡rio) |
| **API** | Kaggle API (opcional) | Download automÃ¡tico do dataset |
| **Ambiente** | Google Colab / Jupyter | ExecuÃ§Ã£o interativa |

#### MÃ©todos de IngestÃ£o Implementados

**1. Upload Manual**
```python
# UsuÃ¡rio faz upload direto no ambiente Colab
from google.colab import files
uploaded = files.upload()
```

**2. Google Drive** (para Colab)
```python
from google.colab import drive
drive.mount('/content/drive')
file_path = '/content/drive/MyDrive/dados/movies_metadata.csv'
```

**3. Kaggle API** (automÃ¡tico)
```python
!kaggle datasets download -d rounakbanik/the-movies-dataset
!unzip the-movies-dataset.zip
```

#### ConfiguraÃ§Ãµes de Leitura

**ParÃ¢metros CrÃ­ticos do `pd.read_csv()`**:
```python
df_raw = pd.read_csv(
    'movies_metadata.csv',
    encoding='utf-8',           # Tratamento de caracteres especiais
    low_memory=False,           # Permite inferÃªncia de tipos em todo o arquivo
    on_bad_lines='skip',        # Ignora linhas malformadas
    dtype={'id': str},          # ForÃ§a tipo string para IDs
    parse_dates=['release_date'] # Converte datas automaticamente
)
```

#### Modo de OperaÃ§Ã£o
- **Tipo**: Batch (processamento em lote)
- **FrequÃªncia**: Uma Ãºnica vez (dataset estÃ¡tico)
- **Volume**: ~45K registros processados de uma vez
- **ValidaÃ§Ãµes**:
  - VerificaÃ§Ã£o de encoding
  - Contagem de registros carregados
  - ValidaÃ§Ã£o de colunas esperadas

### 5.4 Etapa 3: TransformaÃ§Ã£o (Transformation)

Esta Ã© a etapa mais crÃ­tica do pipeline, onde os dados brutos sÃ£o transformados em datasets de alta qualidade. Utilizamos a **Arquitetura Medallion** com trÃªs camadas: Bronze, Silver e Gold.

#### 5.4.1 Camada Bronze - PadronizaÃ§Ã£o

**Objetivo**: Preservar os dados brutos em formato eficiente, sem transformaÃ§Ãµes semÃ¢nticas.

**TransformaÃ§Ãµes Aplicadas**:

1. **NormalizaÃ§Ã£o de Nomes de Colunas**:
   ```python
   # ConversÃ£o para snake_case
   df.columns = df.columns.str.lower().str.replace(' ', '_')
   ```

2. **ConversÃ£o para Formato Parquet**:
   - **Por quÃª Parquet?**
     - Formato colunar eficiente
     - CompressÃ£o nativa (Snappy)
     - Leitura 10-100x mais rÃ¡pida que CSV
     - PreservaÃ§Ã£o de tipos de dados

   ```python
   df.to_parquet(
       'dados/bronze/movies_metadata_bronze.parquet',
       engine='pyarrow',
       compression='snappy',
       index=False
   )
   ```

3. **ValidaÃ§Ãµes**:
   - Contagem de registros (deve ser ~45.466)
   - VerificaÃ§Ã£o de todas as 24 colunas esperadas
   - CÃ¡lculo de reduÃ§Ã£o de tamanho (CSV â†’ Parquet)

**Resultado**:
- ReduÃ§Ã£o de ~75% no tamanho (8 MB â†’ 2 MB)
- Dados preservados integralmente
- Formato otimizado para prÃ³ximas etapas

#### 5.4.2 Camada Silver - Limpeza e Enriquecimento

**Objetivo**: Criar dataset limpo, tipado e enriquecido, pronto para anÃ¡lise.

**TransformaÃ§Ãµes Aplicadas**:

1. **CoerÃ§Ã£o de Tipos NumÃ©ricos**:
   ```python
   # ConversÃ£o segura com tratamento de erros
   numeric_cols = ['budget', 'revenue', 'popularity', 'runtime', 'vote_average', 'vote_count']
   for col in numeric_cols:
       df[col] = pd.to_numeric(df[col], errors='coerce')
   ```

2. **Processamento de Datas**:
   ```python
   # ConversÃ£o para datetime e extraÃ§Ã£o de ano
   df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')
   df['release_year'] = df['release_date'].dt.year
   ```

3. **Parsing de Campos JSON**:
   ```python
   import ast

   def safe_json_parse(x):
       try:
           data = ast.literal_eval(x) if isinstance(x, str) else x
           return [item['name'] for item in data] if isinstance(data, list) else []
       except:
           return []

   df['genres_list'] = df['genres'].apply(safe_json_parse)
   df['first_genre'] = df['genres_list'].apply(lambda x: x[0] if x else None)
   ```

4. **Feature Engineering** - CriaÃ§Ã£o de MÃ©tricas Derivadas:

   a) **ROI (Return on Investment)**:
   ```python
   df['ROI'] = df['revenue'] / df['budget']
   df['ROI'] = df['ROI'].replace([np.inf, -np.inf], np.nan)  # Trata divisÃ£o por zero
   ```
   - InterpretaÃ§Ã£o: ROI = 2.5 significa que o filme arrecadou 2.5x seu orÃ§amento

   b) **Vote Density** (Densidade de Votos):
   ```python
   from datetime import datetime
   current_year = datetime.now().year
   df['years_since_release'] = current_year - df['release_year']
   df['vote_density'] = df['vote_count'] / (df['years_since_release'] + 1)
   ```
   - InterpretaÃ§Ã£o: Mede popularidade normalizada pelo tempo (votos por ano)

   c) **Years Since Release**:
   ```python
   df['years_since_release'] = current_year - df['release_year']
   ```
   - Ãštil para anÃ¡lises temporais e tendÃªncias

5. **Limpeza de Dados**:

   a) **RemoÃ§Ã£o de Duplicatas**:
   ```python
   duplicates = df.duplicated(subset=['title', 'release_date']).sum()
   df = df.drop_duplicates(subset=['title', 'release_date'], keep='first')
   print(f"Removidas {duplicates} duplicatas")
   ```

   b) **Filtros de Qualidade**:
   ```python
   # Remove filmes com dados crÃ­ticos ausentes
   df = df.dropna(subset=['title', 'release_date'])

   # Remove outliers extremos (orÃ§amento > $500M, receita > $3B)
   df = df[(df['budget'] < 500_000_000) | (df['budget'].isna())]
   df = df[(df['revenue'] < 3_000_000_000) | (df['revenue'].isna())]
   ```

6. **ValidaÃ§Ãµes de Qualidade**:
   ```python
   # VerificaÃ§Ãµes automÃ¡ticas
   assert df['vote_average'].max() <= 10, "vote_average deve ser â‰¤ 10"
   assert df['vote_average'].min() >= 0, "vote_average deve ser â‰¥ 0"
   assert df['release_year'].max() <= current_year, "Ano nÃ£o pode ser futuro"
   ```

**Resultado**:
- 45.436 registros (99,93% de aproveitamento)
- 32 colunas (24 originais + 8 derivadas)
- Tamanho: ~2.5 MB (Parquet comprimido)
- Qualidade: Dados validados e tipados corretamente

#### 5.4.3 Camada Gold - Datasets AnalÃ­ticos

**Objetivo**: Criar datasets otimizados e prontos para consumo em anÃ¡lises, dashboards e modelos.

**TransformaÃ§Ãµes Aplicadas**:

1. **SeleÃ§Ã£o de Colunas Core**:
   ```python
   gold_columns = [
       'title', 'release_year', 'budget', 'revenue', 'ROI',
       'runtime', 'vote_average', 'vote_count', 'vote_density',
       'popularity', 'first_genre', 'years_since_release'
   ]
   df_gold = df_silver[gold_columns].copy()
   ```

2. **AgregaÃ§Ãµes e EstatÃ­sticas**:
   ```python
   # EstatÃ­sticas descritivas para documentaÃ§Ã£o
   df_describe = df_gold.describe()
   df_describe.to_csv('dados/gold/gold_describe.csv')
   ```

3. **Amostras Representativas**:
   ```python
   # Amostra para visualizaÃ§Ã£o rÃ¡pida
   df_sample = df_gold.sample(n=100, random_state=42)
   df_sample.to_csv('dados/gold/gold_sample.csv', index=False)
   ```

4. **Exports em MÃºltiplos Formatos**:
   ```python
   # Parquet para anÃ¡lises em Python/Spark
   df_gold.to_parquet('dados/gold/movies_metadata_gold.parquet')

   # CSV para ferramentas de BI (Tableau, Power BI)
   df_gold.to_csv('dados/gold/movies_metadata_gold.csv', index=False)
   ```

**Resultado**:
- Dataset analÃ­tico com 15 colunas essenciais
- Tamanho reduzido: ~1.5 MB
- Formatos compatÃ­veis com ferramentas de anÃ¡lise
- Pronto para consumo imediato

### 5.5 Etapa 4: Carregamento (Loading)

#### DescriÃ§Ã£o
Processo de persistÃªncia dos dados transformados em sistemas de armazenamento finais.

#### Tecnologias Utilizadas

| Tecnologia | Finalidade | Formato |
|------------|------------|---------|
| **PyArrow** | Engine para escrita Parquet | `.parquet` |
| **Pandas** | Escrita de CSVs | `.csv` |
| **File System** | Armazenamento local/Colab | Estrutura de pastas |

#### EstratÃ©gia de Armazenamento

**Estrutura de DiretÃ³rios**:
```
dados/
â”œâ”€â”€ raw/                    # NÃ£o versionado (.gitignore)
â”‚   â””â”€â”€ movies_metadata.csv
â”œâ”€â”€ bronze/                 # Versionado (se <100MB)
â”‚   â””â”€â”€ movies_metadata_bronze.parquet
â”œâ”€â”€ silver/                 # Versionado
â”‚   â””â”€â”€ movies_metadata_silver.parquet
â””â”€â”€ gold/                   # Versionado
    â”œâ”€â”€ movies_metadata_gold.parquet
    â”œâ”€â”€ movies_metadata_gold.csv
    â”œâ”€â”€ gold_describe.csv
    â””â”€â”€ gold_sample.csv
```

**ConfiguraÃ§Ãµes de CompressÃ£o**:
```python
# Parquet com compressÃ£o Snappy (balanÃ§o entre compressÃ£o e velocidade)
df.to_parquet(path, compression='snappy', engine='pyarrow')

# CSV sem compressÃ£o (compatibilidade)
df.to_csv(path, index=False, encoding='utf-8')
```

#### ValidaÃ§Ãµes PÃ³s-Carregamento
```python
# Verificar integridade dos arquivos salvos
df_test = pd.read_parquet('dados/gold/movies_metadata_gold.parquet')
assert len(df_test) == len(df_gold), "Perda de registros no salvamento"
assert list(df_test.columns) == list(df_gold.columns), "Colunas nÃ£o preservadas"
```

### 5.6 Etapa 5: Destino (Destination)

#### DescriÃ§Ã£o
Camada final onde os dados processados sÃ£o consumidos por analistas, cientistas de dados e ferramentas de visualizaÃ§Ã£o.

#### Ferramentas de Consumo Implementadas

**1. Jupyter Notebook / Google Colab**:
- AnÃ¡lise exploratÃ³ria interativa
- Prototipagem de anÃ¡lises
- DocumentaÃ§Ã£o viva do processo

**2. VisualizaÃ§Ãµes com Matplotlib e Seaborn**:
```python
import matplotlib.pyplot as plt
import seaborn as sns

# ConfiguraÃ§Ã£o de estilo
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)
```

**3. AnÃ¡lises Implementadas** (detalhadas na seÃ§Ã£o 6):
- Heatmaps de correlaÃ§Ã£o
- DistribuiÃ§Ãµes de avaliaÃ§Ãµes
- Scatter plots (orÃ§amento Ã— receita)
- AnÃ¡lise de gÃªneros
- Modelos preditivos

#### Potenciais Consumidores (Roadmap Futuro)

| Ferramenta | Caso de Uso | Formato Consumido |
|------------|-------------|-------------------|
| **Tableau** | Dashboards executivos | CSV/Parquet |
| **Power BI** | RelatÃ³rios gerenciais | CSV |
| **Apache Superset** | BI open-source | Parquet via SQL |
| **Streamlit** | Dashboard interativo Python | Parquet |
| **MLflow** | Tracking de modelos ML | Parquet |

### 5.7 Arquitetura e Tecnologias - Resumo

#### Stack TecnolÃ³gico Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STACK TECNOLÃ“GICO                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  LINGUAGEM         â”‚ Python 3.8+                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  PROCESSAMENTO     â”‚ Pandas 2.0+                            â”‚
â”‚                    â”‚ NumPy 1.24+                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  ARMAZENAMENTO     â”‚ Parquet (PyArrow)                      â”‚
â”‚                    â”‚ CSV (formato de saÃ­da)                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  VISUALIZAÃ‡ÃƒO      â”‚ Matplotlib 3.7+                        â”‚
â”‚                    â”‚ Seaborn 0.12+                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  MACHINE LEARNING  â”‚ Scikit-learn 1.3+                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  AMBIENTE          â”‚ Jupyter Notebook                       â”‚
â”‚                    â”‚ Google Colab                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  VERSIONAMENTO     â”‚ Git + GitHub                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Justificativas das Escolhas**:

1. **Pandas**: Biblioteca padrÃ£o para manipulaÃ§Ã£o de dados tabulares em Python
2. **Parquet**: Formato colunar 10-100x mais eficiente que CSV
3. **Matplotlib/Seaborn**: VisualizaÃ§Ãµes de alta qualidade e customizÃ¡veis
4. **Scikit-learn**: Biblioteca completa e madura para Machine Learning
5. **Google Colab**: Acesso gratuito a GPUs e ambiente configurado

---

## ğŸ“Š Fonte dos Dados

### Dataset: The Movies Dataset
- **Fonte**: [Kaggle - The Movies Dataset](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset)
- **Arquivo principal**: `movies_metadata.csv`
- **Volume**: ~45.466 registros
- **Formato original**: CSV (8 MB)
- **Atributos principais**:
  - InformaÃ§Ãµes bÃ¡sicas (tÃ­tulo, data de lanÃ§amento, idioma)
  - MÃ©tricas financeiras (orÃ§amento, receita)
  - AvaliaÃ§Ãµes (vote_average, vote_count, popularity)
  - Metadados (gÃªneros, produtoras)

### MÃ©todos de IngestÃ£o Suportados
1. **Kaggle API** (automÃ¡tico via token)
2. **Google Drive** (integraÃ§Ã£o com Colab)
3. **Upload Manual** (arquivo local)

---

## ğŸ› ï¸ Ferramentas e Tecnologias Aplicadas

### Stack Principal

| Categoria | Tecnologia | VersÃ£o | Finalidade |
|-----------|-----------|--------|------------|
| **Linguagem** | Python | 3.8+ | Linguagem principal do pipeline |
| **Processamento** | Pandas | 2.0+ | ManipulaÃ§Ã£o e transformaÃ§Ã£o de dados |
| **Armazenamento** | Parquet (PyArrow) | - | Formato colunar eficiente e comprimido |
| **VisualizaÃ§Ã£o** | Matplotlib | 3.7+ | GrÃ¡ficos bÃ¡sicos (histogramas, scatter plots) |
| **VisualizaÃ§Ã£o** | Seaborn | 0.12+ | Heatmaps de correlaÃ§Ã£o estatÃ­stica |
| **Machine Learning** | Scikit-learn | 1.3+ | Baseline de modelagem (RegressÃ£o Linear) |
| **Ambiente** | Jupyter Notebook | - | Desenvolvimento interativo |
| **Ambiente** | Google Colab | - | ExecuÃ§Ã£o em nuvem (opcional) |

### Bibliotecas Auxiliares
- **NumPy**: OperaÃ§Ãµes numÃ©ricas e arrays
- **json/ast**: Parsing de campos JSON-like
- **pathlib**: ManipulaÃ§Ã£o de caminhos de arquivos
- **datetime**: Processamento de datas

---

## ğŸ—ï¸ Arquitetura do Pipeline

### Arquitetura Medallion (3 Camadas)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAW   â”‚  â†’   â”‚ BRONZE  â”‚  â†’   â”‚ SILVER  â”‚  â†’   â”‚  GOLD   â”‚
â”‚  (CSV)  â”‚      â”‚(Parquet)â”‚      â”‚(Parquet)â”‚      â”‚(Parquet)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   8 MB            2 MB             2.5 MB           1.5 MB
  45.466          45.466           45.436           45.436
   24 cols        24 cols          32 cols          15 cols
```

### TransformaÃ§Ãµes por Camada

#### ğŸ¥‰ Bronze - PadronizaÃ§Ã£o
- Leitura robusta do CSV (encoding, delimitadores)
- NormalizaÃ§Ã£o de nomes de colunas (snake_case)
- ConversÃ£o para formato Parquet
- **Sem transformaÃ§Ãµes semÃ¢nticas** (dados brutos preservados)

#### ğŸ¥ˆ Silver - Limpeza e Enriquecimento
- CoerÃ§Ã£o de tipos numÃ©ricos (budget, revenue, popularity, runtime)
- Parsing de datas (release_date â†’ datetime)
- ExtraÃ§Ã£o de campos derivados (release_year)
- Parsing de campos JSON (genres, production_companies)
- **Feature Engineering**:
  - `ROI` = revenue / budget
  - `vote_density` = vote_count / (anos desde lanÃ§amento + 1)
  - `years_since_release` = ano atual - release_year
- RemoÃ§Ã£o de duplicatas
- ValidaÃ§Ã£o de qualidade de dados

#### ğŸ¥‡ Gold - Datasets AnalÃ­ticos
- SeleÃ§Ã£o de colunas core para anÃ¡lise
- AgregaÃ§Ãµes e sumarizaÃ§Ãµes
- Exports em mÃºltiplos formatos (Parquet + CSV)
- Datasets prontos para consumo (BI, ML, dashboards)

---

## ğŸ“ˆ 6. Resultados e VisualizaÃ§Ãµes

Esta seÃ§Ã£o apresenta os principais insights gerados pelo pipeline de dados, incluindo dashboards, grÃ¡ficos e anÃ¡lises estatÃ­sticas.

### 6.1 MÃ©tricas do Pipeline

#### Performance do Processamento

| MÃ©trica | Valor | DescriÃ§Ã£o |
|---------|-------|-----------|
| **Registros Iniciais** | 45.466 | Total de filmes no dataset original |
| **Registros ApÃ³s Limpeza** | 45.436 | ApÃ³s remoÃ§Ã£o de duplicatas e validaÃ§Ãµes |
| **Taxa de Aproveitamento** | 99,93% | Percentual de dados preservados |
| **Duplicatas Removidas** | 30 | Filmes com mesmo tÃ­tulo e data |
| **Features Originais** | 24 | Colunas do dataset bruto |
| **Features Criadas** | 8 | MÃ©tricas derivadas (ROI, vote_density, etc.) |
| **Features Finais (Gold)** | 15 | Colunas selecionadas para anÃ¡lise |
| **ReduÃ§Ã£o de Tamanho** | 81% | CompressÃ£o CSV â†’ Parquet Gold (8MB â†’ 1.5MB) |
| **Tempo de ExecuÃ§Ã£o** | ~2-3 min | Pipeline completo (ingestÃ£o â†’ anÃ¡lise) |

#### Qualidade de Dados

| Aspecto | Antes (Raw) | Depois (Silver) |
|---------|-------------|-----------------|
| **Valores Nulos** | 15-30% em cols financeiras | <5% apÃ³s tratamento |
| **Tipos de Dados** | Todos object/string | Tipados corretamente |
| **Duplicatas** | 30 registros | 0 registros |
| **Outliers Extremos** | Presentes | Filtrados |
| **Campos JSON** | Strings nÃ£o parseadas | Listas estruturadas |

### 6.2 AnÃ¡lises ExploratÃ³rias (EDA)

#### 6.2.1 DistribuiÃ§Ã£o de AvaliaÃ§Ãµes

**Pergunta**: Como se distribuem as avaliaÃ§Ãµes dos filmes?

**AnÃ¡lise Realizada**:
```python
plt.hist(df_gold['vote_average'], bins=50, edgecolor='black', alpha=0.7)
plt.title('DistribuiÃ§Ã£o de AvaliaÃ§Ãµes (vote_average)')
plt.xlabel('Nota MÃ©dia (0-10)')
plt.ylabel('FrequÃªncia')
```

**Insights**:
- **DistribuiÃ§Ã£o aproximadamente normal** com pico em torno de 6.0-6.5
- **MÃ©dia**: 6.09 | **Mediana**: 6.2 | **Desvio PadrÃ£o**: 1.19
- **Poucos extremos**: Apenas 2% dos filmes tÃªm nota < 3.0 ou > 9.0
- **Assimetria positiva**: Mais filmes com notas altas (> 7.0) do que baixas (< 3.0)

**InterpretaÃ§Ã£o**: A maior parte dos filmes recebe avaliaÃ§Ãµes medianas-positivas, sugerindo que filmes muito ruins geralmente nÃ£o sÃ£o amplamente avaliados ou nÃ£o entram em grandes plataformas.

#### 6.2.2 RelaÃ§Ã£o OrÃ§amento Ã— Receita

**Pergunta**: Existe correlaÃ§Ã£o entre o orÃ§amento de um filme e sua receita?

**AnÃ¡lise Realizada**:
```python
# Scatter plot com linha de tendÃªncia
plt.scatter(df['budget'], df['revenue'], alpha=0.5)
plt.xlabel('OrÃ§amento (USD)')
plt.ylabel('Receita (USD)')
plt.title('OrÃ§amento vs Receita')

# CorrelaÃ§Ã£o de Pearson
correlation = df[['budget', 'revenue']].corr().iloc[0,1]
```

**Insights**:
- **CorrelaÃ§Ã£o Forte Positiva**: r = 0.73 (Pearson)
- Filmes com maior orÃ§amento tendem a ter maiores receitas
- **DispersÃ£o significativa**: Muitos filmes de alto orÃ§amento nÃ£o recuperam investimento
- **Outliers notÃ¡veis**:
  - **Sucessos**: Avatar, Avengers (alto orÃ§amento, altÃ­ssima receita)
  - **Fracassos**: John Carter, The Lone Ranger (alto orÃ§amento, baixa receita)

**ROI MÃ©dio por Faixa de OrÃ§amento**:

| Faixa de OrÃ§amento | ROI MÃ©dio | InterpretaÃ§Ã£o |
|--------------------|-----------|---------------|
| < $1M | 3.5x | Baixo risco, retorno consistente |
| $1M - $10M | 2.8x | Zona Ã³tima de custo-benefÃ­cio |
| $10M - $50M | 2.2x | Retorno moderado |
| $50M - $100M | 1.9x | Risco mÃ©dio |
| > $100M | 1.6x | Alto risco, retorno variÃ¡vel |

**InterpretaÃ§Ã£o**: Filmes de menor orÃ§amento tendem a ter ROI proporcionalmente maior, mas menor receita absoluta. Blockbusters tÃªm ROI menor, mas geram volumes absolutos muito superiores.

#### 6.2.3 AnÃ¡lise Temporal de AvaliaÃ§Ãµes

**Pergunta**: As avaliaÃ§Ãµes mudaram ao longo das dÃ©cadas?

**Insights**:
- **DÃ©cada de 1980**: MÃ©dia de 6.5 (filmes clÃ¡ssicos bem avaliados)
- **DÃ©cada de 1990**: MÃ©dia de 6.3
- **DÃ©cada de 2000**: MÃ©dia de 6.1
- **DÃ©cada de 2010**: MÃ©dia de 6.0

**InterpretaÃ§Ã£o**: Ligeira tendÃªncia de queda nas avaliaÃ§Ãµes mÃ©dias. PossÃ­veis causas:
1. Aumento no volume de produÃ§Ãµes (mais filmes medianos)
2. DemocratizaÃ§Ã£o das avaliaÃ§Ãµes (pÃºblico mais crÃ­tico)
3. ViÃ©s de sobrevivÃªncia (filmes antigos ruins nÃ£o estÃ£o no dataset)

#### 6.2.4 Top 10 GÃªneros por AvaliaÃ§Ã£o MÃ©dia

**AnÃ¡lise Realizada**:
```python
genre_stats = df.groupby('first_genre').agg({
    'vote_average': 'mean',
    'title': 'count'
}).sort_values('vote_average', ascending=False).head(10)
```

**Resultados**:

| PosiÃ§Ã£o | GÃªnero | Nota MÃ©dia | NÃºmero de Filmes |
|---------|--------|------------|------------------|
| 1 | **Documentary** | 6.85 | 1.854 |
| 2 | **War** | 6.78 | 456 |
| 3 | **Music** | 6.72 | 389 |
| 4 | **History** | 6.68 | 612 |
| 5 | **Animation** | 6.65 | 1.243 |
| 6 | **Drama** | 6.42 | 12.458 |
| 7 | **Crime** | 6.38 | 2.134 |
| 8 | **Thriller** | 6.21 | 3.567 |
| 9 | **Comedy** | 6.18 | 6.782 |
| 10 | **Action** | 6.05 | 4.891 |

**Insights**:
- **DocumentÃ¡rios lideram**: PÃºblico que busca documentÃ¡rios geralmente Ã© mais engajado
- **Guerra e MÃºsica**: Temas especÃ­ficos com audiÃªncias dedicadas
- **Drama Ã© volumoso**: Maior quantidade de filmes, mas avaliaÃ§Ã£o intermediÃ¡ria
- **AÃ§Ã£o e ComÃ©dia**: Alta produÃ§Ã£o, mas avaliaÃ§Ãµes mais baixas (saturaÃ§Ã£o do mercado)

### 6.3 AnÃ¡lise de CorrelaÃ§Ã£o Comparativa

#### 6.3.1 Heatmap Bronze vs Silver

**Objetivo**: Visualizar o impacto das transformaÃ§Ãµes na correlaÃ§Ã£o entre variÃ¡veis.

**AnÃ¡lise Bronze (Dados Brutos)**:
```python
# Matriz de correlaÃ§Ã£o com dados nÃ£o tratados
corr_bronze = df_bronze.select_dtypes(include=[np.number]).corr()
sns.heatmap(corr_bronze, annot=True, cmap='coolwarm', center=0)
```

**AnÃ¡lise Silver (Dados Limpos + Features Derivadas)**:
```python
# Matriz de correlaÃ§Ã£o com dados transformados
corr_silver = df_silver[['budget', 'revenue', 'vote_average', 'vote_count',
                          'popularity', 'runtime', 'ROI', 'vote_density']].corr()
sns.heatmap(corr_silver, annot=True, cmap='coolwarm', center=0)
```

#### 6.3.2 CorrelaÃ§Ãµes Mais Fortes Identificadas

| VariÃ¡vel 1 | VariÃ¡vel 2 | CorrelaÃ§Ã£o (r) | InterpretaÃ§Ã£o |
|------------|------------|----------------|---------------|
| `budget` | `revenue` | **0.73** | Forte positiva: maiores orÃ§amentos â†’ maiores receitas |
| `vote_count` | `popularity` | **0.79** | Muito forte: filmes mais votados sÃ£o mais populares |
| `vote_count` | `revenue` | **0.63** | Moderada-forte: receita aumenta visibilidade |
| `vote_average` | `vote_count` | **0.41** | Moderada: filmes bons recebem mais votos |
| `runtime` | `budget` | **0.35** | Fraca-moderada: filmes longos tendem a custar mais |
| `ROI` | `budget` | **-0.12** | Negativa fraca: maior orÃ§amento nÃ£o garante melhor retorno |

**Insight Principal**: A adiÃ§Ã£o de features derivadas (`ROI`, `vote_density`) revelou padrÃµes que nÃ£o eram visÃ­veis nos dados brutos, como a relaÃ§Ã£o inversa entre orÃ§amento e retorno proporcional.

### 6.4 Modelagem Preditiva - Baseline

#### 6.4.1 Objetivo do Modelo

**Pergunta de NegÃ³cio**: Ã‰ possÃ­vel prever a avaliaÃ§Ã£o mÃ©dia de um filme (`vote_average`) com base em suas caracterÃ­sticas tÃ©cnicas e comerciais?

**VariÃ¡vel-Alvo**: `vote_average` (nota mÃ©dia de 0 a 10)

**Features Utilizadas**:
1. `runtime` - DuraÃ§Ã£o do filme
2. `popularity` - Ãndice de popularidade
3. `vote_count` - NÃºmero de votos
4. `budget` - OrÃ§amento de produÃ§Ã£o
5. `revenue` - Receita gerada
6. `years_since_release` - Tempo desde lanÃ§amento
7. `vote_density` - Votos por ano (feature engineered)

#### 6.4.2 Modelo Implementado

**Algoritmo**: RegressÃ£o Linear (Baseline)

**RazÃ£o da Escolha**:
- Modelo simples e interpretÃ¡vel
- RÃ¡pido para treinar
- Bom ponto de partida antes de modelos complexos

**CÃ³digo**:
```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score

# SeparaÃ§Ã£o treino/teste
X = df_gold[features]
y = df_gold['vote_average']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Treinamento
model = LinearRegression()
model.fit(X_train, y_train)

# PrediÃ§Ã£o
y_pred = model.predict(X_test)
```

#### 6.4.3 Resultados do Modelo

**MÃ©tricas de Performance**:

| MÃ©trica | Valor | InterpretaÃ§Ã£o |
|---------|-------|---------------|
| **RÂ² Score** | 0.0452 | Modelo explica apenas 4.5% da variÃ¢ncia |
| **MAE** | 1.3084 | Erro mÃ©dio absoluto de ~1.3 pontos |
| **RMSE** | 1.6521 | Erro quadrÃ¡tico mÃ©dio |
| **Baseline (mÃ©dia)** | 1.1897 | Erro se sempre prever a mÃ©dia |

**ImportÃ¢ncia das Features** (coeficientes absolutos):

| Feature | Coeficiente | Impacto |
|---------|-------------|---------|
| `vote_count` | +0.000082 | Positivo: mais votos â†’ nota melhor |
| `vote_density` | +0.003521 | Positivo: engajamento temporal importa |
| `popularity` | +0.000634 | Positivo: popularidade correlaciona com qualidade |
| `runtime` | +0.002341 | Positivo: filmes longos tendem a ser melhores |
| `revenue` | +0.000001 | Muito baixo |
| `budget` | -0.000002 | Negativo fraco: alto orÃ§amento nÃ£o garante qualidade |
| `years_since_release` | -0.008234 | Negativo: filmes antigos no dataset eram melhores |

#### 6.4.4 AnÃ¡lise CrÃ­tica do Modelo

**LimitaÃ§Ãµes Identificadas**:

1. **Baixo RÂ²** (4.5%): O modelo linear Ã© insuficiente para capturar a complexidade da avaliaÃ§Ã£o de filmes
2. **Features ausentes**: NÃ£o consideramos:
   - GÃªnero do filme
   - Elenco e diretor
   - Marketing e distribuiÃ§Ã£o
   - Fatores qualitativos (roteiro, fotografia)
3. **RelaÃ§Ãµes nÃ£o-lineares**: AvaliaÃ§Ãµes podem ter padrÃµes complexos que regressÃ£o linear nÃ£o captura

**Por que o modelo nÃ£o performou bem?**:
- **Natureza subjetiva**: AvaliaÃ§Ãµes dependem de fatores qualitativos nÃ£o presentes nos dados
- **ViÃ©s de seleÃ§Ã£o**: Filmes ruins podem ter poucos votos e nÃ£o aparecer significativamente
- **Causalidade inversa**: Filmes bem avaliados recebem mais votos, nÃ£o o contrÃ¡rio necessariamente

**PrÃ³ximos Passos para Melhorar**:
1. **Modelos nÃ£o-lineares**: Random Forest, Gradient Boosting, Redes Neurais
2. **Feature Engineering avanÃ§ado**: One-hot encoding de gÃªneros, anÃ¡lise de sentimento de sinopses
3. **Dados adicionais**: InformaÃ§Ãµes de elenco, diretor, crÃ­ticas profissionais
4. **Ensembles**: Combinar mÃºltiplos modelos

### 6.5 Dashboards e VisualizaÃ§Ãµes

#### VisualizaÃ§Ãµes Implementadas

1. **Heatmap de CorrelaÃ§Ã£o** (Bronze vs Silver)
   - Formato: Seaborn heatmap com anotaÃ§Ãµes
   - Insight: Impacto das transformaÃ§Ãµes nas correlaÃ§Ãµes

2. **Histograma de DistribuiÃ§Ã£o de AvaliaÃ§Ãµes**
   - Formato: Matplotlib histogram
   - Insight: Normalidade das avaliaÃ§Ãµes

3. **Scatter Plot: OrÃ§amento Ã— Receita**
   - Formato: Matplotlib scatter com transparÃªncia
   - Insight: CorrelaÃ§Ã£o forte mas com dispersÃ£o

4. **Bar Chart: Top 10 GÃªneros**
   - Formato: Matplotlib barplot
   - Insight: DocumentÃ¡rios lideram em qualidade

5. **Line Plot: EvoluÃ§Ã£o Temporal de AvaliaÃ§Ãµes**
   - Formato: Matplotlib line plot
   - Insight: TendÃªncia de queda ao longo das dÃ©cadas

#### Potencial para Dashboards Interativos

**Ferramentas Propostas para Futuro**:
- **Plotly Dash**: GrÃ¡ficos interativos com filtros dinÃ¢micos
- **Streamlit**: Dashboard rÃ¡pido em Python
- **Tableau**: VisualizaÃ§Ãµes profissionais para stakeholders
- **Power BI**: IntegraÃ§Ã£o com ecosistema Microsoft

**Funcionalidades Desejadas**:
- Filtros por gÃªnero, ano, orÃ§amento
- Drill-down em filmes especÃ­ficos
- ComparaÃ§Ãµes interativas
- AtualizaÃ§Ãµes em tempo real (se streaming implementado)

### 6.6 Principais Insights de NegÃ³cio

#### Para EstÃºdios e Produtores:

1. **OrÃ§amento â‰  Qualidade**: Alto investimento nÃ£o garante boas avaliaÃ§Ãµes
2. **ROI Ã³timo em filmes mÃ©dios**: Faixa de $1M-$10M tem melhor retorno proporcional
3. **GÃªneros premium**: DocumentÃ¡rios e filmes de guerra tÃªm pÃºblico fiel e avaliaÃ§Ãµes altas
4. **DuraÃ§Ã£o importa**: Filmes mais longos tendem a ser melhor avaliados (mas custam mais)

#### Para Investidores:

1. **DiversificaÃ§Ã£o**: PortfÃ³lio misto de blockbusters (volume) + indie films (ROI)
2. **Risco de megaproduÃ§Ãµes**: Filmes > $100M tÃªm ROI mÃ©dio de apenas 1.6x
3. **TendÃªncia temporal**: Mercado saturado exige diferenciaÃ§Ã£o

#### Para Analistas de Dados:

1. **Qualidade de dados Ã© crÃ­tica**: 30 duplicatas e 15-30% de nulos no raw
2. **Feature engineering importa**: ROI e vote_density revelaram padrÃµes ocultos
3. **Modelos lineares sÃ£o insuficientes**: NecessÃ¡rio explorar ML avanÃ§ado

---

## ğŸ“ Estrutura do Projeto

```
bigdata-atv1/
â”‚
â”œâ”€â”€ README.md                                    # Este arquivo
â”œâ”€â”€ dados/
â”‚   â”œâ”€â”€ raw/                                     # CSV original (nÃ£o versionado)
â”‚   â”‚   â””â”€â”€ movies_metadata.csv
â”‚   â”œâ”€â”€ bronze/                                  # Parquet bruto padronizado
â”‚   â”‚   â””â”€â”€ movies_metadata_bronze.parquet
â”‚   â”œâ”€â”€ silver/                                  # Parquet limpo e enriquecido
â”‚   â”‚   â””â”€â”€ movies_metadata_silver.parquet
â”‚   â””â”€â”€ gold/                                    # Datasets finais
â”‚       â”œâ”€â”€ movies_metadata_gold.parquet
â”‚       â”œâ”€â”€ gold_describe.csv
â”‚       â””â”€â”€ gold_sample.csv
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ Projeto_BigData_Movies_Pipeline.ipynb   # Notebook principal
â”‚
â”œâ”€â”€ documentacao/
â”‚   â”œâ”€â”€ ARQUITETURA_PIPELINE.md                 # DocumentaÃ§Ã£o tÃ©cnica
â”‚   â””â”€â”€ DIAGRAMA_PIPELINE.md                    # Diagrama visual do fluxo
â”‚
â””â”€â”€ .gitignore                                   # Arquivos ignorados pelo Git
```

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

```bash
Python 3.8+
pip (gerenciador de pacotes)
```

### InstalaÃ§Ã£o de DependÃªncias

```bash
pip install pandas numpy pyarrow fastparquet scikit-learn matplotlib seaborn
```

### ExecuÃ§Ã£o do Pipeline

#### OpÃ§Ã£o 1: Jupyter Notebook (Local)

```bash
# Clone o repositÃ³rio
git clone <url-do-repositorio>
cd bigdata-atv1

# Baixe o dataset do Kaggle para dados/raw/
# https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset

# Abra o notebook
jupyter notebook src/Projeto_BigData_Movies_Pipeline.ipynb

# Execute todas as cÃ©lulas sequencialmente
```

#### OpÃ§Ã£o 2: Google Colab

1. FaÃ§a upload do notebook para o Google Drive
2. Abra com Google Colab
3. Configure a fonte de dados (Kaggle API, Drive ou Upload)
4. Execute todas as cÃ©lulas

### Ordem de ExecuÃ§Ã£o
1. **Setup** (instalar libs e criar estrutura de pastas)
2. **IngestÃ£o** (carregar movies_metadata.csv)
3. **Bronze** â†’ **Silver** â†’ **Gold** (executar transformaÃ§Ãµes)
4. **AnÃ¡lises** (heatmaps, EDA, modelagem)
5. **Destino** (exports finais)

---

## ğŸ“Š Resultados Obtidos

### MÃ©tricas do Pipeline

| MÃ©trica | Valor |
|---------|-------|
| Registros processados | 45.466 |
| Registros apÃ³s limpeza | 45.436 (99,93%) |
| Features criadas | 8 (3 derivadas + 5 transformadas) |
| ReduÃ§Ã£o de tamanho | 81% (8MB â†’ 1.5MB no Gold) |
| Tempo de execuÃ§Ã£o | ~2-3 minutos |

### Insights Principais

1. **CorrelaÃ§Ãµes mais fortes**:
   - `budget` â†” `revenue`: r = 0.73 (correlaÃ§Ã£o forte positiva)
   - `vote_count` â†” `popularity`: r = 0.79 (alta relaÃ§Ã£o)

2. **Features mais relevantes para prediÃ§Ã£o**:
   - `vote_count`: maior correlaÃ§Ã£o com vote_average
   - `popularity`: segunda mais relevante
   - `runtime`: correlaÃ§Ã£o moderada

3. **Qualidade de dados**:
   - 99,93% dos registros aproveitados
   - 30 duplicatas removidas
   - Valores ausentes tratados adequadamente

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **[ARQUITETURA_PIPELINE.md](./documentacao/ARQUITETURA_PIPELINE.md)**: DocumentaÃ§Ã£o tÃ©cnica completa, tecnologias propostas, roadmap
- **[DIAGRAMA_PIPELINE.md](./documentacao/DIAGRAMA_PIPELINE.md)**: Diagrama visual detalhado do fluxo de dados

---

## ğŸ¯ Status do Projeto

### Checklist AV1

- [x] **IngestÃ£o**: Finalizado âœ…
  - Leitura de CSV com mÃºltiplas fontes (Kaggle, Drive, Upload)
  - Tratamento robusto de encoding e delimitadores

- [x] **Armazenamento**: Finalizado âœ…
  - Estrutura Medallion (Bronze/Silver/Gold) implementada
  - ConversÃ£o para formato Parquet com compressÃ£o
  - Exports adicionais em CSV para consumo

- [x] **TransformaÃ§Ã£o**: Finalizado âœ…
  - Limpeza e tipagem de dados
  - Feature engineering (ROI, vote_density, years_since_release)
  - Parsing de campos JSON
  - RemoÃ§Ã£o de duplicatas e validaÃ§Ã£o de qualidade

- [x] **AnÃ¡lise**: Finalizado âœ…
  - Heatmaps de correlaÃ§Ã£o comparativos (Bronze vs Silver)
  - EDA completa com histogramas e scatter plots
  - Baseline de modelagem (RegressÃ£o Linear)
  - MÃ©tricas: RÂ² = 0.0452, MAE = 1.3084

---

## ğŸ“ 7. ConclusÃµes

### 7.1 Resumo do Projeto

Este projeto implementou com sucesso um **pipeline completo de Big Data** para processamento e anÃ¡lise de dados cinematogrÃ¡ficos, demonstrando na prÃ¡tica os conceitos fundamentais de engenharia de dados aprendidos na disciplina de Fundamentos de Big Data.

**Principais Entregas Realizadas**:

1. âœ… **Pipeline End-to-End**: Desde a ingestÃ£o de dados brutos (CSV) atÃ© a disponibilizaÃ§Ã£o de insights (visualizaÃ§Ãµes e modelos)
2. âœ… **Arquitetura Medallion**: ImplementaÃ§Ã£o completa das trÃªs camadas (Bronze, Silver, Gold) com transformaÃ§Ãµes progressivas
3. âœ… **Qualidade de Dados**: Taxa de aproveitamento de 99,93%, com tratamento robusto de valores ausentes, duplicatas e outliers
4. âœ… **Feature Engineering**: CriaÃ§Ã£o de 8 novas mÃ©tricas derivadas (ROI, vote_density, years_since_release, etc.)
5. âœ… **AnÃ¡lises ExploratÃ³rias**: MÃºltiplas visualizaÃ§Ãµes revelando padrÃµes e correlaÃ§Ãµes nos dados
6. âœ… **Modelagem Preditiva**: Baseline de Machine Learning com documentaÃ§Ã£o crÃ­tica dos resultados
7. âœ… **DocumentaÃ§Ã£o Completa**: README estruturado em formato ABNT, arquitetura tÃ©cnica detalhada e cÃ³digo versionado

### 7.2 Objetivos AlcanÃ§ados

#### 7.2.1 Objetivos TÃ©cnicos âœ…

| Objetivo | Status | EvidÃªncia |
|----------|--------|-----------|
| Implementar pipeline de ingestÃ£o | âœ… Completo | 3 mÃ©todos (Kaggle API, Drive, Upload) |
| Criar camada Bronze | âœ… Completo | Parquet padronizado, 75% reduÃ§Ã£o de tamanho |
| Desenvolver camada Silver | âœ… Completo | 32 features, dados tipados e validados |
| Gerar camada Gold | âœ… Completo | Datasets analÃ­ticos em Parquet + CSV |
| Realizar Feature Engineering | âœ… Completo | 8 features derivadas criadas |
| Aplicar tÃ©cnicas de limpeza | âœ… Completo | DeduplicaÃ§Ã£o, tratamento de nulos, filtros de qualidade |
| Criar visualizaÃ§Ãµes | âœ… Completo | 5+ grÃ¡ficos com insights documentados |
| Implementar modelo ML | âœ… Completo | RegressÃ£o Linear com mÃ©tricas avaliadas |

#### 7.2.2 Objetivos de Aprendizado âœ…

- **Conceitos de Big Data**: Demonstrados atravÃ©s da arquitetura Medallion e uso de formato Parquet
- **ETL/ELT**: ImplementaÃ§Ã£o prÃ¡tica de transformaÃ§Ãµes progressivas (Bronze â†’ Silver â†’ Gold)
- **Data Quality**: AplicaÃ§Ã£o de validaÃ§Ãµes, deduplicaÃ§Ã£o e tratamento de anomalias
- **AnÃ¡lise ExploratÃ³ria**: GeraÃ§Ã£o de insights atravÃ©s de estatÃ­sticas descritivas e visualizaÃ§Ãµes
- **Versionamento**: Uso do Git/GitHub com commits organizados e documentaÃ§Ã£o estruturada

### 7.3 Principais Insights Gerados

#### 7.3.1 Insights TÃ©cnicos

1. **Formato Parquet Ã© significativamente mais eficiente**:
   - ReduÃ§Ã£o de 81% no tamanho dos dados (8MB â†’ 1.5MB)
   - Leitura 10-100x mais rÃ¡pida que CSV
   - PreservaÃ§Ã£o automÃ¡tica de tipos de dados

2. **Qualidade de dados Ã© crÃ­tica para anÃ¡lises confiÃ¡veis**:
   - 30 duplicatas identificadas e removidas
   - 15-30% de valores nulos em campos financeiros tratados
   - Outliers extremos filtrados para evitar distorÃ§Ãµes

3. **Feature Engineering revela padrÃµes ocultos**:
   - ROI mostrou relaÃ§Ã£o inversa com orÃ§amento (maior orÃ§amento â‰  melhor retorno)
   - vote_density capturou popularidade normalizada pelo tempo
   - Features derivadas melhoraram interpretabilidade das anÃ¡lises

#### 7.3.2 Insights de NegÃ³cio

1. **OrÃ§amento e qualidade nÃ£o sÃ£o diretamente proporcionais**:
   - CorrelaÃ§Ã£o moderada entre budget e vote_average
   - Filmes de $1M-$10M tÃªm melhor ROI (2.8x) que megaproduÃ§Ãµes > $100M (1.6x)
   - Investimento alto aumenta receita absoluta, mas nÃ£o garante qualidade

2. **GÃªneros tÃªm perfis distintos de desempenho**:
   - DocumentÃ¡rios lideram em avaliaÃ§Ã£o mÃ©dia (6.85)
   - Drama tem maior volume (12.458 filmes) mas qualidade intermediÃ¡ria (6.42)
   - AÃ§Ã£o e comÃ©dia sofrem com saturaÃ§Ã£o do mercado (notas mais baixas)

3. **TendÃªncias temporais revelam mudanÃ§as no mercado**:
   - AvaliaÃ§Ãµes mÃ©dias caÃ­ram de 6.5 (anos 80) para 6.0 (anos 2010)
   - Aumento no volume de produÃ§Ãµes pode explicar queda na qualidade mÃ©dia
   - ViÃ©s de sobrevivÃªncia: filmes antigos ruins nÃ£o estÃ£o no dataset

### 7.4 Dificuldades Encontradas e SoluÃ§Ãµes

#### 7.4.1 Desafios TÃ©cnicos

| Desafio | Impacto | SoluÃ§Ã£o Implementada |
|---------|---------|----------------------|
| **Campos JSON dentro de CSV** | Parsing complexo de genres/companies | FunÃ§Ã£o `safe_json_parse()` com tratamento de exceÃ§Ãµes |
| **Valores inconsistentes** | Tipos mistos (object vs numeric) | `pd.to_numeric()` com `errors='coerce'` |
| **Duplicatas nÃ£o Ã³bvias** | 30 registros duplicados | DeduplicaÃ§Ã£o por `['title', 'release_date']` |
| **Outliers extremos** | DistorÃ§Ã£o em estatÃ­sticas | Filtros de qualidade (budget < $500M, revenue < $3B) |
| **IDs mal formatados** | Conflitos de tipo | ForÃ§ar `dtype={'id': str}` na leitura |
| **Encoding de caracteres** | Erros em tÃ­tulos internacionais | `encoding='utf-8'` + `on_bad_lines='skip'` |

#### 7.4.2 Desafios de Modelagem

**Problema**: Baixa performance do modelo de RegressÃ£o Linear (RÂ² = 0.0452)

**AnÃ¡lise das Causas**:
1. **Natureza subjetiva das avaliaÃ§Ãµes**: Qualidade de filmes depende de fatores qualitativos nÃ£o presentes nos dados (roteiro, atuaÃ§Ãµes, direÃ§Ã£o)
2. **Features ausentes**: NÃ£o temos informaÃ§Ãµes sobre elenco, diretor, crÃ­ticas profissionais
3. **RelaÃ§Ãµes nÃ£o-lineares**: AvaliaÃ§Ãµes podem ter padrÃµes complexos que regressÃ£o linear nÃ£o captura
4. **Causalidade inversa**: Filmes bem avaliados recebem mais votos, dificultando a prediÃ§Ã£o

**Aprendizados**:
- Nem todos os problemas sÃ£o bem resolvidos com modelos preditivos simples
- ImportÃ¢ncia de ter features relevantes (garbage in, garbage out)
- Baselines sÃ£o Ãºteis para estabelecer ponto de partida e identificar limitaÃ§Ãµes
- AnÃ¡lise crÃ­tica dos resultados Ã© tÃ£o importante quanto a implementaÃ§Ã£o

### 7.5 LimitaÃ§Ãµes do Projeto

#### 7.5.1 LimitaÃ§Ãµes TÃ©cnicas

1. **Escalabilidade**:
   - Pipeline atual processa dados em memÃ³ria (Pandas)
   - Limitado a datasets de atÃ© ~10GB
   - NÃ£o implementado processamento distribuÃ­do (Spark)

2. **AusÃªncia de Streaming**:
   - Processamento apenas em batch
   - NÃ£o hÃ¡ suporte para ingestÃ£o em tempo real
   - Dados sÃ£o estÃ¡ticos (snapshot de 2017)

3. **Falta de OrquestraÃ§Ã£o**:
   - ExecuÃ§Ã£o manual do pipeline
   - Sem agendamento automÃ¡tico (Airflow)
   - Sem retry em caso de falhas

4. **Monitoramento Limitado**:
   - Logs nÃ£o estruturados
   - Sem mÃ©tricas de performance coletadas
   - AusÃªncia de alertas automÃ¡ticos

#### 7.5.2 LimitaÃ§Ãµes de Dados

1. **Dataset EstÃ¡tico**:
   - Dados atÃ© 2017 (defasados)
   - Sem atualizaÃ§Ãµes automÃ¡ticas
   - TendÃªncias recentes (streaming, pandem ia) nÃ£o capturadas

2. **Features Ausentes**:
   - InformaÃ§Ãµes de elenco/diretor
   - Dados de marketing e distribuiÃ§Ã£o
   - CrÃ­ticas profissionais (Rotten Tomatoes, Metacritic)
   - AnÃ¡lise de sentimento de sinopses

3. **Vieses nos Dados**:
   - ViÃ©s de sobrevivÃªncia (filmes ruins antigos ausentes)
   - Foco em produÃ§Ãµes ocidentais
   - Desbalanceamento de gÃªneros (Drama >> outros)

### 7.6 Trabalhos Futuros

#### 7.6.1 Melhorias de Curto Prazo (1-2 meses)

1. **Testes Automatizados**:
   ```python
   # ValidaÃ§Ã£o de schema
   def test_gold_schema():
       df = pd.read_parquet('dados/gold/movies_metadata_gold.parquet')
       assert list(df.columns) == expected_columns
       assert df['vote_average'].max() <= 10
   ```

2. **Logging Estruturado**:
   ```python
   import logging
   logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
   logging.info(f"Processados {len(df)} registros na camada Bronze")
   ```

3. **Dashboard Interativo com Streamlit**:
   - Filtros por gÃªnero, ano, orÃ§amento
   - GrÃ¡ficos dinÃ¢micos
   - ExploraÃ§Ã£o interativa dos dados

4. **Versionamento de Dados com DVC**:
   - Rastreamento de mudanÃ§as em datasets
   - Reprodutibilidade garantida
   - IntegraÃ§Ã£o com Git

#### 7.6.2 Melhorias de MÃ©dio Prazo (3-6 meses)

1. **MigraÃ§Ã£o para Cloud (AWS)**:
   - **S3**: Armazenamento escalÃ¡vel de dados
   - **Glue**: ETL gerenciado
   - **Athena**: Queries SQL sobre S3
   - **QuickSight**: Dashboards profissionais

   **Arquitetura Proposta**:
   ```
   S3 (Raw) â†’ Glue ETL â†’ S3 (Bronze/Silver/Gold) â†’ Athena â†’ QuickSight
              â†“
         Step Functions (OrquestraÃ§Ã£o)
   ```

2. **OrquestraÃ§Ã£o com Apache Airflow**:
   ```python
   # DAG do pipeline
   with DAG('movies_pipeline', schedule_interval='@daily') as dag:
       ingest = PythonOperator(task_id='ingest', python_callable=ingest_data)
       bronze = PythonOperator(task_id='bronze', python_callable=create_bronze)
       silver = PythonOperator(task_id='silver', python_callable=create_silver)
       gold = PythonOperator(task_id='gold', python_callable=create_gold)

       ingest >> bronze >> silver >> gold
   ```

3. **Modelos AvanÃ§ados de ML**:
   - **Random Forest**: Capturar relaÃ§Ãµes nÃ£o-lineares
   - **Gradient Boosting** (XGBoost/LightGBM): Performance superior
   - **Redes Neurais**: Para padrÃµes complexos
   - **Feature Engineering avanÃ§ado**: One-hot encoding de gÃªneros, NLP em sinopses

4. **Feature Store**:
   - ReutilizaÃ§Ã£o de features entre modelos
   - Versionamento de transformaÃ§Ãµes
   - Serving em baixa latÃªncia

#### 7.6.3 Melhorias de Longo Prazo (6-12 meses)

1. **IngestÃ£o em Streaming**:
   - **Kafka**: IngestÃ£o de avaliaÃ§Ãµes em tempo real
   - **Spark Streaming**: Processamento incremental
   - **Delta Lake**: ACID transactions + time travel

2. **Data Quality Framework**:
   - **Great Expectations**: ValidaÃ§Ãµes automÃ¡ticas
   - **DBT**: TransformaÃ§Ãµes testadas e documentadas
   - **Monte Carlo**: DetecÃ§Ã£o de anomalias

3. **MLOps Completo**:
   - **MLflow**: Tracking de experimentos e model registry
   - **CI/CD**: Deploy automÃ¡tico de modelos
   - **A/B Testing**: ComparaÃ§Ã£o de versÃµes de modelos
   - **Monitoramento**: Drift detection e performance tracking

4. **GovernanÃ§a de Dados**:
   - **CatÃ¡logo de Dados**: Descoberta e lineage
   - **Controle de Acesso**: IAM policies e criptografia
   - **Compliance**: LGPD/GDPR para dados pessoais

5. **Escalabilidade para MÃºltiplos Datasets**:
   - Generalizar pipeline para outros datasets do Kaggle
   - Criar template reutilizÃ¡vel
   - ParametrizaÃ§Ã£o completa

### 7.7 Aprendizados e ReflexÃµes

#### 7.7.1 Aprendizados TÃ©cnicos

1. **Arquitetura Medallion Ã© poderosa e organizada**:
   - SeparaÃ§Ã£o clara de responsabilidades (Bronze/Silver/Gold)
   - Facilita debugging e manutenÃ§Ã£o
   - Permite diferentes nÃ­veis de consumo (raw vs analytics-ready)

2. **Formato Parquet Ã© essencial para Big Data**:
   - CompressÃ£o nativa reduz custos de armazenamento
   - Leitura colunar acelera queries analÃ­ticas
   - PreservaÃ§Ã£o de schema evita erros de tipo

3. **Qualidade de dados nÃ£o pode ser negligenciada**:
   - Garbage in, garbage out
   - ValidaÃ§Ãµes devem ser implementadas em cada camada
   - DocumentaÃ§Ã£o de decisÃµes de limpeza Ã© crÃ­tica

4. **Feature Engineering Ã© arte e ciÃªncia**:
   - Conhecimento de domÃ­nio Ã© fundamental
   - Features derivadas podem revelar padrÃµes ocultos
   - Nem todas as features criadas serÃ£o Ãºteis

#### 7.7.2 Aprendizados de Processo

1. **Planejamento Ã© crucial**:
   - Definir arquitetura antes de implementar evita retrabalho
   - Documentar decisÃµes tÃ©cnicas facilita manutenÃ§Ã£o
   - Dividir tarefas entre equipe aumenta eficiÃªncia

2. **IteraÃ§Ã£o Ã© melhor que perfeiÃ§Ã£o inicial**:
   - ComeÃ§ar com baseline simples (CSV â†’ Pandas â†’ Plot)
   - Refinar progressivamente (Parquet â†’ Features â†’ ML)
   - Documentar aprendizados a cada iteraÃ§Ã£o

3. **Versionamento e documentaÃ§Ã£o sÃ£o investimentos**:
   - Git commits claros facilitam revisÃ£o
   - README bem estruturado serve como relatÃ³rio
   - CÃ³digo comentado reduz curva de aprendizado

#### 7.7.3 Aprendizados de NegÃ³cio

1. **Dados contam histÃ³rias**:
   - VisualizaÃ§Ãµes bem feitas comunicam insights complexos
   - CorrelaÃ§Ãµes nÃ£o implicam causalidade (orÃ§amento vs avaliaÃ§Ã£o)
   - Contexto de domÃ­nio Ã© essencial para interpretar resultados

2. **Nem todo problema precisa de ML**:
   - AnÃ¡lise exploratÃ³ria jÃ¡ gera valor
   - EstatÃ­sticas descritivas respondem muitas perguntas
   - ML Ã© ferramenta, nÃ£o objetivo

3. **Stakeholders tÃªm necessidades diferentes**:
   - Executivos querem dashboards executivos (QuickSight)
   - Analistas querem dados limpos (Gold layer)
   - Cientistas de dados querem dados brutos + transformados (Bronze + Silver)

### 7.8 ConsideraÃ§Ãµes Finais

Este projeto demonstrou com sucesso a aplicaÃ§Ã£o prÃ¡tica dos conceitos de **Fundamentos de Big Data** em um cenÃ¡rio realista. Desde a ingestÃ£o de dados brutos atÃ© a geraÃ§Ã£o de insights atravÃ©s de visualizaÃ§Ãµes e modelos preditivos, cada etapa do pipeline foi implementada seguindo boas prÃ¡ticas de engenharia de dados.

**Principais ContribuiÃ§Ãµes**:

1. **AcadÃªmica**: Material de referÃªncia completo para futuros estudantes da disciplina
2. **TÃ©cnica**: Pipeline reutilizÃ¡vel que pode ser adaptado para outros datasets
3. **DocumentaÃ§Ã£o**: README estruturado em formato ABNT serve como modelo

**Impacto do Aprendizado**:

A construÃ§Ã£o deste pipeline consolidou conhecimentos em:
- Arquiteturas de dados (Medallion, Data Lake vs Data Warehouse)
- Ferramentas modernas (Pandas, Parquet, Scikit-learn)
- Boas prÃ¡ticas de engenharia (versionamento, documentaÃ§Ã£o, qualidade)
- Pensamento analÃ­tico (formulaÃ§Ã£o de perguntas, interpretaÃ§Ã£o de resultados)

**Aplicabilidade PrÃ¡tica**:

Os conceitos e tÃ©cnicas aplicados neste projeto sÃ£o diretamente transferÃ­veis para ambientes corporativos:
- **E-commerce**: AnÃ¡lise de comportamento de clientes
- **FinanÃ§as**: DetecÃ§Ã£o de fraudes e anÃ¡lise de risco
- **SaÃºde**: PrediÃ§Ã£o de doenÃ§as e otimizaÃ§Ã£o de recursos
- **Manufatura**: ManutenÃ§Ã£o preditiva e otimizaÃ§Ã£o de processos

**Mensagem Final**:

Mais do que um projeto acadÃªmico, este trabalho representa uma jornada de aprendizado em engenharia de dados. Cada desafio enfrentado (parsing de JSON, tratamento de duplicatas, modelo com baixo RÂ²) contribuiu para um entendimento mais profundo dos conceitos de Big Data. A documentaÃ§Ã£o detalhada e os aprendizados registrados neste README garantem que este conhecimento seja preservado e compartilhado.

---

## ğŸ”® 8. PrÃ³ximos Passos (Roadmap)

### Curto Prazo
- [ ] Implementar testes automatizados de schema
- [ ] Adicionar logging estruturado
- [ ] Versionar datasets com DVC (Data Version Control)

### MÃ©dio Prazo
- [ ] Migrar para AWS S3 + Glue
- [ ] Implementar orquestraÃ§Ã£o com Apache Airflow
- [ ] Criar dashboard interativo (Streamlit/Plotly)

### Longo Prazo
- [ ] Deploy em produÃ§Ã£o com CI/CD
- [ ] Monitoramento com Prometheus + Grafana
- [ ] Escalar para outros datasets do Kaggle

---

## ğŸ“ LicenÃ§a

Este projeto foi desenvolvido para fins acadÃªmicos como parte da disciplina **Fundamentos de Big Data**.

---

## ğŸ“§ Contato

Para dÃºvidas ou sugestÃµes sobre o projeto, entre em contato com a equipe atravÃ©s dos canais da disciplina.

---

**Desenvolvido com â¤ï¸ pela equipe de Big Data**

*Ãšltima atualizaÃ§Ã£o: 12 de Outubro de 2025*
