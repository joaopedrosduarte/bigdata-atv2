# Arquitetura do Pipeline de Dados - Movies Dataset

> **üìä Diagrama Visual**: Para visualizar o fluxo completo do pipeline, consulte [DIAGRAMA_PIPELINE.md](./DIAGRAMA_PIPELINE.md)

---

## 1. Vis√£o Geral da Arquitetura

Este projeto implementa um **pipeline de dados em batch** seguindo a **arquitetura Medallion** (Bronze ‚Üí Silver ‚Üí Gold) para processar e analisar o dataset "The Movies Dataset" do Kaggle.

### Principais Caracter√≠sticas

- **Dataset**: ~45K registros de filmes (movies_metadata.csv)
- **Arquitetura**: Medallion (3 camadas)
- **Formato de Armazenamento**: Parquet (colunar, comprimido)
- **Processamento**: Python + Pandas
- **An√°lises**: EDA com heatmaps de correla√ß√£o + Baseline de ML

### Fluxo Resumido

```
RAW (CSV) ‚Üí BRONZE (Parquet) ‚Üí SILVER (Parquet limpo) ‚Üí GOLD (Parquet + CSV) ‚Üí Consumo
```

---

## 2. Tecnologias Utilizadas e Propostas de Refinamento

### 2.1 Tecnologias Atualmente Implementadas (Open Source)

| Componente | Tecnologia | Justificativa |
|------------|------------|---------------|
| **Processamento** | Python + Pandas | Simplicidade, biblioteca madura para manipula√ß√£o de dados tabulares |
| **Armazenamento** | Parquet (Apache Arrow) | Formato colunar eficiente, compress√£o nativa, compat√≠vel com Big Data |
| **An√°lise Explorat√≥ria** | Matplotlib + Seaborn | Visualiza√ß√µes simples (Matplotlib) e heatmaps estat√≠sticos avan√ßados (Seaborn) |
| **Modelagem** | Scikit-learn | Biblioteca padr√£o para ML em Python, ideal para baseline |
| **Ambiente** | Jupyter Notebook / Google Colab | Prototipagem r√°pida, documenta√ß√£o viva |

### 2.2 Limita√ß√µes da Arquitetura Atual

- **Escalabilidade**: Pandas processa dados em mem√≥ria (limitado a ~10GB)
- **Processamento Distribu√≠do**: N√£o utiliza paraleliza√ß√£o em cluster
- **Orquestra√ß√£o**: Execu√ß√£o manual, sem agendamento autom√°tico
- **Monitoramento**: Sem rastreamento de m√©tricas ou logs estruturados
- **Versionamento de Dados**: Sem controle de vers√µes dos datasets

### 2.3 Tecnologias Propostas para Refinamento (Pagas/Enterprise)

#### **Op√ß√£o 1: Stack AWS (Cloud-Native)**

| Componente | Tecnologia | Custo Estimado | Justificativa |
|------------|------------|----------------|---------------|
| **Ingest√£o** | AWS S3 + AWS Glue | ~$50-200/m√™s | Escal√°vel, serverless, integra√ß√£o nativa com ecossistema AWS |
| **Processamento** | AWS EMR (Spark) | ~$300-800/m√™s | Processamento distribu√≠do, suporta PB de dados, otimizado para Parquet |
| **Orquestra√ß√£o** | AWS Step Functions / Airflow (MWAA) | ~$100-300/m√™s | Workflows visuais, retry autom√°tico, integra√ß√£o com Lambda |
| **Armazenamento** | S3 (Data Lake) | ~$20-50/m√™s | Dur√°vel, versionado, suporta particionamento |
| **Cat√°logo de Dados** | AWS Glue Data Catalog | ~$10-30/m√™s | Descoberta autom√°tica de schemas, integra√ß√£o com Athena |
| **Query Engine** | AWS Athena | Pay-per-query (~$5/TB) | SQL sobre S3, sem infraestrutura |
| **Dashboards** | Amazon QuickSight | ~$24/usu√°rio/m√™s | Visualiza√ß√µes interativas, ML insights integrados |

**Custo Total Estimado**: ~$500-1.400/m√™s (produ√ß√£o small-medium scale)

**Justificativa da Escolha**:
- **Escalabilidade el√°stica**: Paga apenas pelo uso
- **Integra√ß√£o nativa**: Todos os servi√ßos se comunicam nativamente
- **Seguran√ßa**: IAM roles, encryption at rest/in transit
- **Maturidade**: Ampla ado√ß√£o no mercado

#### **Op√ß√£o 2: Stack Databricks (Lakehouse Architecture)**

| Componente | Tecnologia | Custo Estimado | Justificativa |
|------------|------------|----------------|---------------|
| **Plataforma Unificada** | Databricks Lakehouse | ~$800-2.000/m√™s | Spark otimizado, Delta Lake, notebooks colaborativos |
| **Armazenamento** | Delta Lake (S3/ADLS) | ~$50-100/m√™s | ACID transactions, time travel, schema evolution |
| **Orquestra√ß√£o** | Databricks Workflows | Inclu√≠do | Integrado √† plataforma, UI/UX superior |
| **Feature Store** | Databricks Feature Store | Inclu√≠do | Versionamento de features, reutiliza√ß√£o entre modelos |
| **ML** | MLflow (gerenciado) | Inclu√≠do | Tracking de experimentos, model registry |
| **Dashboards** | Databricks SQL Dashboards | ~$0,22/DBU | SQL analytics sobre Delta Lake |

**Custo Total Estimado**: ~$900-2.200/m√™s

**Justificativa da Escolha**:
- **Performance**: 5-10x mais r√°pido que Spark vanilla (cache otimizado)
- **Lakehouse**: Une benef√≠cios de Data Lake + Data Warehouse
- **Colabora√ß√£o**: Notebooks multi-linguagem, Git integration
- **Governan√ßa**: Unity Catalog para controle de acesso fino

#### **Op√ß√£o 3: Stack Google Cloud (Serverless-First)**

| Componente | Tecnologia | Custo Estimado | Justificativa |
|------------|------------|----------------|---------------|
| **Ingest√£o** | Cloud Storage + Dataflow | ~$100-300/m√™s | Streaming + Batch unificado, auto-scaling |
| **Processamento** | BigQuery | ~$5/TB consultado | Serverless, escal√°vel a PB, SQL padr√£o |
| **Orquestra√ß√£o** | Cloud Composer (Airflow) | ~$200-400/m√™s | Airflow gerenciado, integra√ß√£o com GCP |
| **Feature Engineering** | Vertex AI Feature Store | ~$50-150/m√™s | Features prontas para ML, versionamento |
| **ML** | Vertex AI | Pay-per-use (~$100-500/m√™s) | AutoML, custom training, model deployment |
| **Dashboards** | Looker Studio | Gr√°tis - $30/usu√°rio | Integra√ß√£o nativa com BigQuery |

**Custo Total Estimado**: ~$500-1.500/m√™s

**Justificativa da Escolha**:
- **Simplicidade**: Menos componentes para gerenciar
- **Serverless**: Zero manuten√ß√£o de clusters
- **BigQuery**: Excelente para queries anal√≠ticas complexas
- **Looker**: Dashboards de alta qualidade

### 2.4 Recomenda√ß√£o Final

**Para este projeto acad√™mico ‚Üí Stack AWS** pelos seguintes motivos:

1. **Custo-benef√≠cio**: AWS Free Tier permite experimenta√ß√£o gratuita
2. **Documenta√ß√£o**: Ampla comunidade e tutoriais
3. **Flexibilidade**: F√°cil migra√ß√£o entre servi√ßos (EMR ‚Üí Glue ‚Üí Athena)
4. **Aprendizado**: Skills mais demandadas no mercado brasileiro

**Arquitetura Recomendada**:
```
S3 (Raw) ‚Üí AWS Glue ETL ‚Üí S3 (Bronze/Silver/Gold) ‚Üí Athena (Query) ‚Üí QuickSight (Viz)
         ‚Üì
    Step Functions (Orquestra√ß√£o)
```

---

## 3. Arquitetura Parcial Implementada

### 3.1 Ambiente Atual (Simulado Localmente)

```
/dados
  /raw          ‚Üê CSV original (n√£o versionado)
  /bronze       ‚Üê Parquet padronizado
  /silver       ‚Üê Parquet limpo e enriquecido
  /gold         ‚Üê Datasets finais (Parquet + CSV)
```

### 3.2 Componentes Implementados

#### **‚úÖ Ingest√£o**
- [x] Leitura de CSV com tratamento de erros
- [x] Suporte a m√∫ltiplas fontes (Upload, Drive, Kaggle API)
- [x] Valida√ß√£o b√°sica de integridade

#### **‚úÖ Armazenamento**
- [x] Estrutura de diret√≥rios Bronze/Silver/Gold
- [x] Convers√£o para Parquet (compress√£o snappy)
- [x] Preserva√ß√£o de schema

#### **‚úÖ Transforma√ß√£o**
- [x] **Bronze**: Normaliza√ß√£o de nomes de colunas
- [x] **Silver**:
  - Tipagem de dados num√©ricos e datas
  - Parsing de campos JSON (genres)
  - Feature engineering (ROI, vote_density)
  - Deduplica√ß√£o
- [x] **Gold**:
  - Sele√ß√£o de colunas core
  - Exports para CSV (amostras e estat√≠sticas)

#### **‚úÖ An√°lise**
- [x] **An√°lise de Correla√ß√£o**:
  - Heatmap comparativo Bronze vs Silver (lado a lado)
  - Identifica√ß√£o de correla√ß√µes fortes (|r| > 0.5)
  - Justificativa para sele√ß√£o de features
- [x] **EDA b√°sica**:
  - Histogramas de distribui√ß√£o (vote_average)
  - Scatter plots (or√ßamento vs receita)
  - Top 10 g√™neros por m√©dia de nota
- [x] **Baseline de modelagem**:
  - Regress√£o Linear para predi√ß√£o de vote_average
  - M√©tricas: R¬≤ e MAE (Mean Absolute Error)

### 3.3 Componentes N√ÉO Implementados (Pr√≥ximos Passos)

#### **‚è≥ Orquestra√ß√£o**
- [ ] Agendamento autom√°tico de pipelines
- [ ] Retry em caso de falhas
- [ ] Notifica√ß√µes de status

#### **‚è≥ Monitoramento**
- [ ] Logs estruturados
- [ ] M√©tricas de performance
- [ ] Alertas de anomalias

#### **‚è≥ Qualidade de Dados**
- [ ] Testes automatizados de schema
- [ ] Valida√ß√£o de business rules
- [ ] Profiling de dados

#### **‚è≥ Streaming**
- [ ] Ingest√£o em tempo real
- [ ] Processamento incremental

---

## 4. Equipe Respons√°vel e Divis√£o de Tarefas

### 4.1 Estrutura da Equipe

| Papel | Respons√°vel | Responsabilidades |
|-------|-------------|-------------------|
| **Tech Lead / Arquiteto de Dados** | [Nome] | Defini√ß√£o da arquitetura, escolha de tecnologias, revis√£o t√©cnica |
| **Engenheiro de Dados 1** | [Nome] | Implementa√ß√£o do pipeline Bronze ‚Üí Silver, parsing de JSON, feature engineering |
| **Engenheiro de Dados 2** | [Nome] | Implementa√ß√£o Silver ‚Üí Gold, otimiza√ß√£o de queries, particionamento |
| **Cientista de Dados** | [Nome] | EDA, modelagem, valida√ß√£o de features, an√°lise de resultados |
| **DevOps / MLOps** | [Nome] | Containeriza√ß√£o, CI/CD, monitoramento, deployment |

### 4.2 Divis√£o de Tarefas Detalhada

#### **Sprint 1: Funda√ß√£o (Semanas 1-2)**
- [ ] **Tech Lead**: Definir arquitetura medalion, criar diagrama t√©cnico
- [ ] **Eng. Dados 1**: Implementar camada Bronze (ingest√£o + padroniza√ß√£o)
- [ ] **Eng. Dados 2**: Configurar estrutura de diret√≥rios e versionamento
- [ ] **Cientista de Dados**: An√°lise explorat√≥ria do CSV raw
- [ ] **DevOps**: Setup do ambiente (Colab, Git, requisitos)

#### **Sprint 2: Transforma√ß√£o (Semanas 3-4)**
- [ ] **Eng. Dados 1**:
  - Implementar camada Silver (limpeza, tipagem)
  - Parsing de campos JSON (genres, companies)
  - Tratamento de valores faltantes
- [ ] **Eng. Dados 2**:
  - Feature engineering (ROI, vote_density)
  - Deduplica√ß√£o e filtros de qualidade
- [ ] **Cientista de Dados**:
  - Definir features relevantes para modelagem
  - An√°lise de correla√ß√µes
- [ ] **DevOps**: Configurar notebooks parametrizados

#### **Sprint 3: Analytics (Semanas 5-6)**
- [ ] **Eng. Dados 2**:
  - Implementar camada Gold
  - Criar agrega√ß√µes e sumariza√ß√µes
  - Exportar CSVs para consumo
- [ ] **Cientista de Dados**:
  - EDA completa (visualiza√ß√µes)
  - Baseline de modelagem (regress√£o linear)
  - Documentar insights
- [ ] **DevOps**:
  - Automatizar execu√ß√£o do pipeline
  - Configurar exports autom√°ticos

#### **Sprint 4: Documenta√ß√£o e Entrega (Semana 7)**
- [ ] **Tech Lead**:
  - Revisar c√≥digo e arquitetura
  - Preparar apresenta√ß√£o t√©cnica
- [ ] **Eng. Dados 1 & 2**:
  - Refatora√ß√£o e otimiza√ß√£o
  - Testes de qualidade
- [ ] **Cientista de Dados**:
  - Finalizar relat√≥rio de an√°lise
  - Documentar limita√ß√µes e pr√≥ximos passos
- [ ] **DevOps**:
  - README t√©cnico
  - Guia de execu√ß√£o

### 4.3 Cerim√¥nias √Ågeis

| Cerim√¥nia | Frequ√™ncia | Dura√ß√£o | Objetivo |
|-----------|-----------|---------|----------|
| **Daily Standup** | Di√°rio | 15 min | Sincroniza√ß√£o de progresso e bloqueios |
| **Sprint Planning** | In√≠cio de cada sprint | 2h | Definir escopo e estimar tarefas |
| **Code Review** | Ad-hoc | 30 min | Garantir qualidade e compartilhar conhecimento |
| **Sprint Review** | Final de cada sprint | 1h | Demonstrar funcionalidades implementadas |
| **Retrospectiva** | Final de cada sprint | 1h | Melhorias de processo |

### 4.4 Ferramentas de Colabora√ß√£o

- **C√≥digo**: GitHub (branches: `main`, `dev`, `feature/*`)
- **Tarefas**: GitHub Projects / Trello
- **Documenta√ß√£o**: Markdown (versionado no Git)
- **Comunica√ß√£o**: Slack / Discord
- **Notebooks**: Google Colab (compartilhado)

---

## 5. Pr√≥ximos Passos e Roadmap

### Curto Prazo (1-2 meses)
1. Implementar testes automatizados de schema
2. Adicionar logging estruturado
3. Criar dashboard b√°sico com Plotly/Streamlit
4. Versionar datasets com DVC (Data Version Control)

### M√©dio Prazo (3-6 meses)
1. Migrar para AWS S3 + Glue
2. Implementar orquestra√ß√£o com Airflow
3. Adicionar camada de streaming (simulada com Kafka)
4. Criar feature store para reutiliza√ß√£o

### Longo Prazo (6-12 meses)
1. Deploy em produ√ß√£o com CI/CD
2. Monitoramento com Prometheus + Grafana
3. Implementar data quality checks autom√°ticos
4. Escalar para outros datasets do Kaggle

---

## 6. Refer√™ncias T√©cnicas

- [Databricks Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)
- [AWS Data Lake Best Practices](https://aws.amazon.com/big-data/datalakes-and-analytics/)
- [Google Cloud Data Engineering](https://cloud.google.com/architecture/data-lifecycle-cloud-platform)
- [The Movies Dataset - Kaggle](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset)

---

**Documento gerado em:** 2025-10-12
**Vers√£o:** 1.1
**Status:** Implementa√ß√£o conclu√≠da (AV1)
**√öltima atualiza√ß√£o:** 2025-10-12
