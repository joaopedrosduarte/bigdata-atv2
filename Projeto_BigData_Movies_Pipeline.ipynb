{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7bdadf17",
      "metadata": {
        "id": "7bdadf17"
      },
      "source": [
        "\n",
        "# Projeto: Predição e Insights de Filmes — *The Movies Dataset*\n",
        "\n",
        "**Disciplina:** Fundamentos de Big Data  \n",
        "**Notebook:** Pipeline completo (bronze → silver → gold), EDA e baseline de modelagem  \n",
        "**Base:** `movies_metadata.csv` (Kaggle — The Movies Dataset)  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ba5f328",
      "metadata": {
        "id": "0ba5f328"
      },
      "source": [
        "\n",
        "## Objetivos\n",
        "- Montar um **pipeline de dados** de ponta a ponta cobrindo **Ingestão**, **Transformação**, **Carregamento** e **Destino**.\n",
        "- Padronizar o schema do `movies_metadata.csv`, tratar erros e enriquecer com colunas derivadas.\n",
        "- Entregar **arquivos Parquet** nas camadas **/bronze**, **/silver** e **/gold**.\n",
        "- Realizar **EDA** enxuta e **modelagem baseline** (prever `vote_average` ou `revenue`).\n",
        "- Salvar **insumos finais** (tabelas e gráficos) para consumo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156cd486",
      "metadata": {
        "id": "156cd486"
      },
      "source": [
        "\n",
        "## Estrutura de Projeto (sugerida para o repositório)\n",
        "```\n",
        "/codigo               # scripts python e notebooks (.ipynb)\n",
        "/notebooks            # notebooks intermediários (opcional)\n",
        "/documentacao         # diagrama de arquitetura, PDFs, etc.\n",
        "/dados\n",
        "  /raw                # arquivos originais (não versionar grandes)\n",
        "  /bronze             # parquet/CSV bruto padronizado\n",
        "  /silver             # parquet já limpo/enriquecido\n",
        "  /gold               # datasets finais prontos para análise/modelo\n",
        "README.md\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cf46fc3",
      "metadata": {
        "id": "9cf46fc3"
      },
      "source": [
        "\n",
        "## 0. Setup\n",
        "Execute para instalar/carregar dependências no Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14381377",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14381377",
        "outputId": "12fd9760-62a3-4d42-ec2c-57e744ca77e1"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.11' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Se estiver no Colab, descomente para instalar libs extras (se necessário):\n",
        "# !pip install pyarrow fastparquet scikit-learn pandas numpy matplotlib\n",
        "\n",
        "import os\n",
        "import json\n",
        "import ast\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "BASE_DIR = Path.cwd() / \"dados\"\n",
        "RAW_DIR = BASE_DIR / \"raw\"\n",
        "BRONZE_DIR = BASE_DIR / \"bronze\"\n",
        "SILVER_DIR = BASE_DIR / \"silver\"\n",
        "GOLD_DIR = BASE_DIR / \"gold\"\n",
        "\n",
        "for d in [RAW_DIR, BRONZE_DIR, SILVER_DIR, GOLD_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Estrutura criada em:\", BASE_DIR.resolve())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e30b6587",
      "metadata": {
        "id": "e30b6587"
      },
      "source": [
        "\n",
        "## 1. Ingestão (batch)\n",
        "Escolha uma das opções abaixo:\n",
        "1. **Upload direto** do arquivo `movies_metadata.csv` para a pasta `/dados/raw`.\n",
        "2. **Google Drive**: montar Drive e copiar o CSV para `/dados/raw`.\n",
        "3. **Kaggle API** (no Colab): configurar `kaggle.json` e baixar o dataset (opcional).\n",
        "\n",
        "> **Nota:** Este notebook assume **execução em batch** (lotes). Para simular **streaming**, ver a seção opcional ao final.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f8bbf0d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8bbf0d2",
        "outputId": "195b67ac-d6d2-4446-af76-50a829e9e7e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando arquivo em: /content/dados/raw/movies_metadata.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# === Opção 1: Upload manual ===\n",
        "# from google.colab import files  # no Colab\n",
        "# uploaded = files.upload()       # selecione movies_metadata.csv\n",
        "# for fname in uploaded.keys():\n",
        "#     os.replace(fname, RAW_DIR / fname)\n",
        "# print(\"Arquivos enviados para:\", RAW_DIR)\n",
        "\n",
        "# === Opção 2: Google Drive ===\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !cp \"/content/drive/MyDrive/caminho/para/movies_metadata.csv\" \"{RAW_DIR}\"\n",
        "\n",
        "# === Opção 3: Kaggle API (opcional) ===\n",
        "# !mkdir -p ~/.kaggle\n",
        "# with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
        "#     f.write('{\"username\":\"SEU_USUARIO\",\"key\":\"SUA_CHAVE\"}')\n",
        "# !chmod 600 /root/.kaggle/kaggle.json\n",
        "# !kaggle datasets download -d rounakbanik/the-movies-dataset -f movies_metadata.csv -p \"{RAW_DIR}\"\n",
        "# !unzip -o \"{RAW_DIR / 'movies_metadata.csv.zip'}\" -d \"{RAW_DIR}\"\n",
        "\n",
        "raw_csv = RAW_DIR / \"movies_metadata.csv\"\n",
        "print(\"Esperando arquivo em:\", raw_csv.resolve())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d27f240",
      "metadata": {
        "id": "0d27f240"
      },
      "source": [
        "\n",
        "## 2. Bronze — Padronização mínima do bruto\n",
        "- Leitura robusta (tratando encoding/delimitador).\n",
        "- Padronização de nomes de colunas (lowercase, snake_case).\n",
        "- Salvamento em **Parquet** sem transformar semântica (apenas ajustes mínimos de tipos).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7bcc7fee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bcc7fee",
        "outputId": "994ee68c-0801-4a39-bd18-8fac736d14a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arquivo não encontrado: /content/dados/raw/movies_metadata.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def to_snake(s: str) -> str:\n",
        "    return (s or \"\").strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
        "\n",
        "def read_movies_csv(path: Path) -> pd.DataFrame:\n",
        "    # Leitura tolerante a erros comuns no dataset\n",
        "    df = pd.read_csv(path, low_memory=False)\n",
        "    df.columns = [to_snake(c) for c in df.columns]\n",
        "    return df\n",
        "\n",
        "if raw_csv.exists():\n",
        "    df_raw = read_movies_csv(raw_csv)\n",
        "    print(df_raw.shape, \"linhas, colunas:\", len(df_raw.columns))\n",
        "    df_raw.to_parquet(BRONZE_DIR / \"movies_metadata_bronze.parquet\", index=False)\n",
        "    print(\"Bronze salvo em:\", (BRONZE_DIR / \"movies_metadata_bronze.parquet\").resolve())\n",
        "else:\n",
        "    print(\"Arquivo não encontrado:\", raw_csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15765f9d",
      "metadata": {
        "id": "15765f9d"
      },
      "source": [
        "\n",
        "## 3. Silver — Limpeza e Enriquecimento\n",
        "Tratamentos principais recomendados para `movies_metadata`:\n",
        "- **Tipos**: `budget`, `revenue`, `popularity`, `runtime`, `vote_average`, `vote_count` → numéricos coerentes.\n",
        "- **Datas**: `release_date` → `datetime`; criar `release_year`.\n",
        "- **IDs**: garantir que `id` seja tratável (alguns registros possuem valores inválidos).\n",
        "- **JSON-likes**: colunas como `genres`, `production_companies` etc. → normalizar para listas/strings.\n",
        "- **Filtros**: remover registros com datas inválidas, duplicatas e valores claramente defeituosos.\n",
        "- **Derivadas**: `roi = revenue / budget` (quando `budget > 0`), `vote_density = vote_count / (anos desde lançamento + 1)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd4886e8",
      "metadata": {
        "id": "bd4886e8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def coerce_float(series):\n",
        "    return pd.to_numeric(series, errors=\"coerce\")\n",
        "\n",
        "def parse_date_safe(s):\n",
        "    try:\n",
        "        return pd.to_datetime(s, errors=\"coerce\")\n",
        "    except Exception:\n",
        "        return pd.NaT\n",
        "\n",
        "def parse_json_like(cell):\n",
        "    # Muitas colunas vêm como strings de listas de dicts; tentar ast.literal_eval\n",
        "    if pd.isna(cell) or cell in (\"\", \"[]\", \"{}\"):\n",
        "        return []\n",
        "    try:\n",
        "        obj = ast.literal_eval(cell)\n",
        "        if isinstance(obj, list):\n",
        "            return obj\n",
        "        return []\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "def extract_names(list_of_dicts, key=\"name\"):\n",
        "    try:\n",
        "        return [d.get(key) for d in list_of_dicts if isinstance(d, dict) and key in d]\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "bronze_path = BRONZE_DIR / \"movies_metadata_bronze.parquet\"\n",
        "if bronze_path.exists():\n",
        "    df = pd.read_parquet(bronze_path)\n",
        "\n",
        "    # Tipos numéricos\n",
        "    for col in [\"budget\",\"revenue\",\"popularity\",\"runtime\",\"vote_average\",\"vote_count\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = coerce_float(df[col])\n",
        "\n",
        "    # Datas\n",
        "    if \"release_date\" in df.columns:\n",
        "        df[\"release_date\"] = pd.to_datetime(df[\"release_date\"], errors=\"coerce\")\n",
        "        df[\"release_year\"] = df[\"release_date\"].dt.year\n",
        "\n",
        "    # IDs e títulos\n",
        "    if \"id\" in df.columns:\n",
        "        # Alguns ids são inválidos (ex.: strings com datas). Tornar numérico, onde falhar deixar NaN.\n",
        "        df[\"id_numeric\"] = pd.to_numeric(df[\"id\"], errors=\"coerce\")\n",
        "    if \"title\" in df.columns and \"original_title\" in df.columns:\n",
        "        df[\"title_clean\"] = df[\"title\"].fillna(df[\"original_title\"])\n",
        "\n",
        "    # JSON-like: genres\n",
        "    if \"genres\" in df.columns:\n",
        "        df[\"genres_list\"] = df[\"genres\"].apply(parse_json_like).apply(lambda lst: extract_names(lst, \"name\"))\n",
        "        df[\"genres_str\"] = df[\"genres_list\"].apply(lambda lst: \", \".join([x for x in lst if isinstance(x, str)]))\n",
        "\n",
        "    # Derivadas\n",
        "    if \"budget\" in df.columns and \"revenue\" in df.columns:\n",
        "        df[\"roi\"] = np.where(df[\"budget\"]>0, df[\"revenue\"]/df[\"budget\"], np.nan)\n",
        "    if \"vote_count\" in df.columns and \"release_year\" in df.columns:\n",
        "        current_year = datetime.now().year\n",
        "        df[\"years_since_release\"] = np.where(pd.notna(df[\"release_year\"]), current_year - df[\"release_year\"], np.nan)\n",
        "        df[\"vote_density\"] = np.where((pd.notna(df[\"years_since_release\"])) & (df[\"years_since_release\"] >= 0),\n",
        "                                      df[\"vote_count\"] / (df[\"years_since_release\"] + 1), np.nan)\n",
        "\n",
        "    # Filtros de qualidade básicos\n",
        "    df = df.drop_duplicates(subset=[\"id\",\"title_clean\"], keep=\"first\")\n",
        "    # Filtrar datas muito antigas/invalidas se necessário (opcional)\n",
        "    # df = df[df[\"release_year\"].between(1900, datetime.now().year, inclusive=\"both\")]\n",
        "\n",
        "    silver_path = SILVER_DIR / \"movies_metadata_silver.parquet\"\n",
        "    df.to_parquet(silver_path, index=False)\n",
        "    print(\"Silver salvo em:\", silver_path.resolve(), \"→\", df.shape)\n",
        "else:\n",
        "    print(\"Bronze não encontrado:\", bronze_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d157363",
      "metadata": {
        "id": "0d157363"
      },
      "source": [
        "\n",
        "## 4. Gold — Datasets finais\n",
        "Seleção de colunas úteis para análises/modelos e particionamento simples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a60435c",
      "metadata": {
        "id": "1a60435c"
      },
      "outputs": [],
      "source": [
        "\n",
        "silver_path = SILVER_DIR / \"movies_metadata_silver.parquet\"\n",
        "if silver_path.exists():\n",
        "    df = pd.read_parquet(silver_path)\n",
        "    cols_core = [\n",
        "        \"id_numeric\",\"title_clean\",\"original_language\",\"release_date\",\"release_year\",\n",
        "        \"runtime\",\"popularity\",\"vote_average\",\"vote_count\",\"budget\",\"revenue\",\"roi\",\n",
        "        \"genres_str\",\"years_since_release\",\"vote_density\"\n",
        "    ]\n",
        "    df_gold = df[[c for c in cols_core if c in df.columns]].copy()\n",
        "    out_path = GOLD_DIR / \"movies_metadata_gold.parquet\"\n",
        "    df_gold.to_parquet(out_path, index=False)\n",
        "    print(\"Gold salvo em:\", out_path.resolve(), \"→\", df_gold.shape)\n",
        "else:\n",
        "    print(\"Silver não encontrado:\", silver_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3c3ae45",
      "metadata": {
        "id": "a3c3ae45"
      },
      "source": [
        "\n",
        "## 5. EDA Rápida\n",
        "Alguns gráficos simples para entender distribuição de notas, relação orçamento×receita e gêneros populares.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d693f36",
      "metadata": {
        "id": "9d693f36"
      },
      "outputs": [],
      "source": [
        "\n",
        "gold_path = GOLD_DIR / \"movies_metadata_gold.parquet\"\n",
        "if gold_path.exists():\n",
        "    dfg = pd.read_parquet(gold_path)\n",
        "\n",
        "    # Histograma de notas\n",
        "    plt.figure()\n",
        "    dfg[\"vote_average\"].dropna().plot(kind=\"hist\", bins=20)\n",
        "    plt.title(\"Distribuição de 'vote_average'\")\n",
        "    plt.xlabel(\"vote_average\")\n",
        "    plt.ylabel(\"freq\")\n",
        "    plt.show()\n",
        "\n",
        "    # Dispersão orçamento vs receita (amostra para não poluir)\n",
        "    plt.figure()\n",
        "    sample = dfg.dropna(subset=[\"budget\",\"revenue\"]).sample(min(3000, len(dfg)), random_state=42)\n",
        "    plt.scatter(sample[\"budget\"], sample[\"revenue\"], alpha=0.3)\n",
        "    plt.title(\"Orçamento vs Receita (amostra)\")\n",
        "    plt.xlabel(\"budget\")\n",
        "    plt.ylabel(\"revenue\")\n",
        "    plt.show()\n",
        "\n",
        "    # Top 10 gêneros por média de nota (simples, por ocorrência)\n",
        "    if \"genres_str\" in dfg.columns:\n",
        "        # expandir gêneros\n",
        "        genre_rows = []\n",
        "        for _, row in dfg[[\"genres_str\",\"vote_average\"]].dropna().iterrows():\n",
        "            for g in [x.strip() for x in row[\"genres_str\"].split(\",\") if x.strip()]:\n",
        "                genre_rows.append((g, row[\"vote_average\"]))\n",
        "        if genre_rows:\n",
        "            gdf = pd.DataFrame(genre_rows, columns=[\"genre\",\"vote_average\"])\n",
        "            top = (gdf.groupby(\"genre\")[\"vote_average\"]\n",
        "                      .mean()\n",
        "                      .sort_values(ascending=False)\n",
        "                      .head(10))\n",
        "            plt.figure()\n",
        "            top.plot(kind=\"bar\")\n",
        "            plt.title(\"Top 10 gêneros por média de nota\")\n",
        "            plt.xlabel(\"gênero\")\n",
        "            plt.ylabel(\"média de vote_average\")\n",
        "            plt.xticks(rotation=45, ha=\"right\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "else:\n",
        "    print(\"Gold não encontrado:\", gold_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45672309",
      "metadata": {
        "id": "45672309"
      },
      "source": [
        "\n",
        "## 6. Baseline de Modelagem\n",
        "Como baseline simples, vamos prever `vote_average` a partir de algumas features numéricas.\n",
        "> **Observação:** Este modelo é apenas um ponto de partida para cumprir os requisitos e gerar um insumo analítico.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3612cb",
      "metadata": {
        "id": "dd3612cb"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "gold_path = GOLD_DIR / \"movies_metadata_gold.parquet\"\n",
        "if gold_path.exists():\n",
        "    dfm = pd.read_parquet(gold_path).dropna(subset=[\"vote_average\"])\n",
        "    features = [\"runtime\",\"popularity\",\"vote_count\",\"budget\",\"revenue\",\"years_since_release\",\"vote_density\"]\n",
        "    X = dfm[features].fillna(0)\n",
        "    y = dfm[\"vote_average\"]\n",
        "    if len(X) > 0 and len(y) > 0:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        lr = LinearRegression()\n",
        "        lr.fit(X_train, y_train)\n",
        "        pred = lr.predict(X_test)\n",
        "        print(\"Baseline LinearRegression\")\n",
        "        print(\"R2:\", round(r2_score(y_test, pred), 4))\n",
        "        print(\"MAE:\", round(mean_absolute_error(y_test, pred), 4))\n",
        "    else:\n",
        "        print(\"Dados insuficientes após preparação.\")\n",
        "else:\n",
        "    print(\"Gold não encontrado:\", gold_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b14b368",
      "metadata": {
        "id": "3b14b368"
      },
      "source": [
        "\n",
        "## 7. Destino (consumo)\n",
        "- Os datasets finais estão em `/dados/gold` (formato Parquet).\n",
        "- Gráficos e tabelas podem ser salvos como imagens/CSVs na mesma pasta para consumo por dashboards.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c95c9f",
      "metadata": {
        "id": "89c95c9f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Exemplo: salvar resumo estatístico e amostra dos dados gold\n",
        "gold_path = GOLD_DIR / \"movies_metadata_gold.parquet\"\n",
        "if gold_path.exists():\n",
        "    dfg = pd.read_parquet(gold_path)\n",
        "    dfg.describe(include=\"all\").to_csv(GOLD_DIR / \"gold_describe.csv\")\n",
        "    dfg.sample(min(1000, len(dfg)), random_state=42).to_csv(GOLD_DIR / \"gold_sample.csv\", index=False)\n",
        "    print(\"Arquivos salvos em:\", GOLD_DIR.resolve())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3be601ac",
      "metadata": {
        "id": "3be601ac"
      },
      "source": [
        "\n",
        "## (Opcional) 8. Simulação de *Streaming*\n",
        "Simular ingestão em micro-lotes lendo o CSV linha a linha e gravando *chunks* em `/dados/bronze/stream/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2166a06f",
      "metadata": {
        "id": "2166a06f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Exemplo simples (descomente para testar com arquivo pequeno)\n",
        "# stream_dir = BRONZE_DIR / \"stream\"\n",
        "# stream_dir.mkdir(parents=True, exist_ok=True)\n",
        "# chunk_size = 1000\n",
        "# if raw_csv.exists():\n",
        "#     reader = pd.read_csv(raw_csv, chunksize=chunk_size, low_memory=False)\n",
        "#     for i, chunk in enumerate(reader):\n",
        "#         path = stream_dir / f\"chunk_{i:04d}.parquet\"\n",
        "#         chunk.to_parquet(path, index=False)\n",
        "#         print(\"gravou:\", path)\n",
        "# else:\n",
        "#     print(\"Arquivo não encontrado para stream:\", raw_csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "314eaace",
      "metadata": {
        "id": "314eaace"
      },
      "source": [
        "\n",
        "---\n",
        "### Checklist AV1 (preencher no README)\n",
        "- [ ] Ingestão: Em progresso / Finalizado / Pendente  \n",
        "- [ ] Armazenamento: Em progresso / Finalizado / Pendente  \n",
        "- [ ] Transformação: Em progresso / Finalizado / Pendente  \n",
        "- [ ] Demonstração técnica: pronto para apresentação  \n",
        "\n",
        "> Gerado em: 2025-10-06 13:46:46\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
